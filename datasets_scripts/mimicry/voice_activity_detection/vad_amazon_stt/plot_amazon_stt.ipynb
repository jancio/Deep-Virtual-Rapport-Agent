{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_01_P1_sid_09.flac /media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_01_P2_sid_02.flac /media/DataDrive/MimicryDB/speech_to_text_amazon/sessid_01_.json\n",
      "\tSampling rate: 16000 Length: 9715665\n",
      "\tSampling rate: 16000 Length: 9715665\n",
      "/media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_02_P1_sid_09.flac /media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_02_P2_sid_17.flac /media/DataDrive/MimicryDB/speech_to_text_amazon/sessid_02_.json\n",
      "\tSampling rate: 16000 Length: 15785457\n",
      "\tSampling rate: 16000 Length: 15785457\n",
      "/media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_03_P1_sid_17.flac /media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_03_P2_sid_02.flac /media/DataDrive/MimicryDB/speech_to_text_amazon/sessid_03_.json\n",
      "\tSampling rate: 16000 Length: 7112811\n",
      "\tSampling rate: 16000 Length: 7112811\n",
      "/media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_04_P1_sid_12.flac /media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_04_P2_sid_23.flac /media/DataDrive/MimicryDB/speech_to_text_amazon/sessid_04_.json\n",
      "\tSampling rate: 16000 Length: 15270014\n",
      "\tSampling rate: 16000 Length: 15270014\n",
      "/media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_05_P1_sid_12.flac /media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_05_P2_sid_21.flac /media/DataDrive/MimicryDB/speech_to_text_amazon/sessid_05_.json\n",
      "\tSampling rate: 16000 Length: 15625032\n",
      "\tSampling rate: 16000 Length: 15625032\n",
      "/media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_06_P1_sid_23.flac /media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_06_P2_sid_21.flac /media/DataDrive/MimicryDB/speech_to_text_amazon/sessid_06_.json\n",
      "\tSampling rate: 16000 Length: 15480318\n",
      "\tSampling rate: 16000 Length: 15480318\n",
      "/media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_07_P1_sid_09.flac /media/DataDrive/MimicryDB/audio_separated_16kHz_flac/sessid_07_P2_sid_01.flac /media/DataDrive/MimicryDB/speech_to_text_amazon/sessid_07_.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-87b632ab0559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Load both audio files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0maudio_signal_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\tSampling rate: {samplerate_1} Length: {len(audio_signal_1)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0maudio_signal_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dvra/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[1;32m    257\u001b[0m                    subtype, endian, format, closefd) as f:\n\u001b[1;32m    258\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malways_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dvra/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, frames, dtype, always_2d, fill_value, out)\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'read'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dvra/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_array_io\u001b[0;34m(self, action, array, frames)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cdata_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dvra/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_cdata_io\u001b[0;34m(self, action, data, ctype, frames)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_snd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sf_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'f_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0m_error_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_errorcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#######################################################################################################################\n",
    "# Project: Deep Virtual Rapport Agent (rapport model)\n",
    "#\n",
    "#     Jan Ondras (jo951030@gmail.com)\n",
    "#     Institute for Creative Technologies, University of Southern California\n",
    "#     April-October 2019\n",
    "#\n",
    "#######################################################################################################################\n",
    "# Plot the outputs from the Amazon speech-to-text\n",
    "#     Supports channel identification (input was stereo audio)\n",
    "#######################################################################################################################\n",
    "\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Path to STT outputs\n",
    "stt_outputs_dir = f'/home/ICT2000/jondras/dvra_datasets/mimicry/voice_activity_detection/speech_to_text_amazon/'\n",
    "mono_audio_dir = '/home/ICT2000/jondras/dvra_datasets/mimicry/audio/audio_separated_16kHz_flac'\n",
    "\n",
    "# Iterate over audio files\n",
    "audio_filenames = sorted(glob.glob(f'{mono_audio_dir}/*.flac'))\n",
    "for i in range(0, len(audio_filenames), 2):\n",
    "        \n",
    "    stt_output_filename = stt_outputs_dir + audio_filenames[i].split('/')[-1][:10] + '.json'\n",
    "    print(audio_filenames[i], audio_filenames[i + 1], stt_output_filename)\n",
    "#     if int(audio_basename[7:9]) < 54:\n",
    "#         continue\n",
    "\n",
    "    # Load both audio files\n",
    "    audio_signal_1, samplerate_1 = sf.read(audio_filenames[i])\n",
    "    print(f'\\tSampling rate: {samplerate_1} Length: {len(audio_signal_1)}')\n",
    "    audio_signal_2, samplerate_2 = sf.read(audio_filenames[i + 1])\n",
    "    print(f'\\tSampling rate: {samplerate_2} Length: {len(audio_signal_2)}')\n",
    "    x_audio_signal = np.arange(0, len(audio_signal_1) / samplerate_1, 1. / samplerate_1)[:len(audio_signal_1)]\n",
    "    \n",
    "    # Load json outputs from STT and generate binary voice activity for each speaker\n",
    "    # Speaker tags are 1 and 2 only\n",
    "    speaker_tags = [1, 2]\n",
    "    # TODO\n",
    "    \n",
    "    print()\n",
    "        \n",
    "print(f'Processed {i + 1} Amazon speech2text output files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sessid_01_P1_sid_09\n",
      "sessid_01_P2_sid_02\n",
      "sessid_02_P1_sid_09\n",
      "sessid_02_P2_sid_17\n",
      "sessid_03_P1_sid_17\n",
      "sessid_03_P2_sid_02\n",
      "sessid_04_P1_sid_12\n",
      "sessid_04_P2_sid_23\n",
      "sessid_05_P1_sid_12\n",
      "sessid_05_P2_sid_21\n",
      "sessid_06_P1_sid_23\n",
      "sessid_06_P2_sid_21\n",
      "sessid_07_P1_sid_09\n",
      "sessid_07_P2_sid_01\n",
      "sessid_08_P1_sid_09\n",
      "sessid_08_P2_sid_04\n",
      "sessid_09_P1_sid_01\n",
      "sessid_09_P2_sid_04\n",
      "sessid_10_P1_sid_09\n",
      "sessid_10_P2_sid_34\n",
      "sessid_11_P1_sid_09\n",
      "sessid_11_P2_sid_15\n",
      "sessid_12_P1_sid_15\n",
      "sessid_12_P2_sid_11\n",
      "sessid_13_P1_sid_09\n",
      "sessid_13_P2_sid_19\n",
      "sessid_14_P1_sid_19\n",
      "sessid_14_P2_sid_06\n",
      "sessid_15_P1_sid_09\n",
      "sessid_15_P2_sid_16\n",
      "sessid_16_P1_sid_24\n",
      "sessid_16_P2_sid_16\n",
      "sessid_17_P1_sid_09\n",
      "sessid_17_P2_sid_43\n",
      "sessid_18_P1_sid_03\n",
      "sessid_18_P2_sid_43\n",
      "sessid_19_P1_sid_09\n",
      "sessid_19_P2_sid_22\n",
      "sessid_20_P1_sid_09\n",
      "sessid_20_P2_sid_50\n",
      "sessid_21_P1_sid_50\n",
      "sessid_21_P2_sid_22\n",
      "sessid_22_P1_sid_12\n",
      "sessid_22_P2_sid_18\n",
      "sessid_23_P1_sid_12\n",
      "sessid_23_P2_sid_39\n",
      "sessid_24_P1_sid_18\n",
      "sessid_24_P2_sid_39\n",
      "sessid_25_P1_sid_12\n",
      "sessid_25_P2_sid_27\n",
      "sessid_26_P1_sid_12\n",
      "sessid_26_P2_sid_32\n",
      "sessid_27_P1_sid_27\n",
      "sessid_27_P2_sid_32\n",
      "sessid_28_P1_sid_09\n",
      "sessid_28_P2_sid_07\n",
      "sessid_29_P1_sid_09\n",
      "sessid_29_P2_sid_05\n",
      "sessid_30_P1_sid_07\n",
      "sessid_30_P2_sid_05\n",
      "sessid_31_P1_sid_28\n",
      "sessid_31_P2_sid_09\n",
      "sessid_32_P1_sid_28\n",
      "sessid_32_P2_sid_14\n",
      "sessid_33_P1_sid_09\n",
      "sessid_33_P2_sid_33\n",
      "sessid_34_P1_sid_09\n",
      "sessid_34_P2_sid_36\n",
      "sessid_35_P1_sid_33\n",
      "sessid_35_P2_sid_36\n",
      "sessid_36_P1_sid_13\n",
      "sessid_36_P2_sid_40\n",
      "sessid_37_P1_sid_13\n",
      "sessid_37_P2_sid_40\n",
      "sessid_38_P1_sid_56\n",
      "sessid_38_P2_sid_30\n",
      "sessid_40_P1_sid_56\n",
      "sessid_40_P2_sid_51\n",
      "sessid_41_P1_sid_57\n",
      "sessid_41_P2_sid_51\n",
      "sessid_42_P1_sid_12\n",
      "sessid_42_P2_sid_10\n",
      "sessid_43_P1_sid_12\n",
      "sessid_43_P2_sid_20\n",
      "sessid_44_P1_sid_10\n",
      "sessid_44_P2_sid_20\n",
      "sessid_45_P1_sid_56\n",
      "sessid_45_P2_sid_38\n",
      "sessid_46_P1_sid_55\n",
      "sessid_46_P2_sid_38\n",
      "sessid_47_P1_sid_56\n",
      "sessid_47_P2_sid_37\n",
      "sessid_48_P1_sid_58\n",
      "sessid_48_P2_sid_37\n",
      "sessid_49_P1_sid_56\n",
      "sessid_49_P2_sid_49\n",
      "sessid_50_P1_sid_12\n",
      "sessid_50_P2_sid_31\n",
      "sessid_51_P1_sid_12\n",
      "sessid_51_P2_sid_59\n",
      "sessid_52_P1_sid_12\n",
      "sessid_52_P2_sid_08\n",
      "sessid_53_P1_sid_59\n",
      "sessid_53_P2_sid_08\n",
      "sessid_54_P1_sid_12\n",
      "\tSampling rate: 16000\n",
      "sessid_54_P2_sid_60\n",
      "\tSampling rate: 16000\n",
      "Processed 106 Google speech2text output files.\n"
     ]
    }
   ],
   "source": [
    "# Plot the outputs from the Google Speech-2-Text\n",
    "# Speaker identification (input was mono audio)\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Path to STT outputs\n",
    "stt_outputs_dir = f'/media/DataDrive/MimicryDB/speech_to_text_amazon'\n",
    "mono_audio_dir = '/media/DataDrive/MimicryDB/audio_separated_16kHz_flac/'\n",
    "\n",
    "# Iterate over csv output files and audio files\n",
    "for i, stt_output_file in enumerate(sorted(glob.glob(f'{stt_outputs_dir}/*.json'))):\n",
    "        \n",
    "    output_filename_split = stt_output_file.split('/')[-1][:-4].split('_')\n",
    "    audio_basename = '_'.join(output_filename_split[:5])\n",
    "    print(audio_basename)\n",
    "#     if int(audio_basename[7:9]) < 54:\n",
    "#         continue\n",
    "\n",
    "    # Load audio signal\n",
    "    audio_signal, samplerate = sf.read(f'{mono_audio_dir}/{audio_basename}.flac')\n",
    "    print(f'\\tSampling rate: {samplerate}')\n",
    "    x_audio_signal = np.arange(0, len(audio_signal) / samplerate, 1. / samplerate)[:len(audio_signal)]\n",
    "    \n",
    "    # Load json dump outputs from STT and generate binary voice activity for each speaker\n",
    "    # Speaker tags are 1 and 2 only\n",
    "    speaker_tags = [1, 2]\n",
    "    bin_voice_activity = dict()\n",
    "    for speaker_tag in speaker_tags:\n",
    "        bin_voice_activity[speaker_tag] = np.zeros(len(audio_signal), dtype=int)\n",
    "        \n",
    "    with open(stt_output_file, \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "#         print(data)\n",
    "\n",
    "        # Check if speaker tags were generated (if yes, take words from the last result only)\n",
    "        if 'speakerTag' in data['results'][-1]['alternatives'][0]['words'][0].keys():\n",
    "            for word in data['results'][-1]['alternatives'][0]['words']:\n",
    "                # Skip \"s\" at the end of the string\n",
    "                start_time = float(word['startTime'][:-1])\n",
    "                end_time = float(word['endTime'][:-1])\n",
    "                bin_voice_activity[word['speakerTag']] = np.where(\n",
    "                    (x_audio_signal >= start_time) & (x_audio_signal <= end_time), \n",
    "                    1, bin_voice_activity[word['speakerTag']])\n",
    "\n",
    "        # If no speaker tags were assigned, take words from all results and assign speaker tag 1\n",
    "        else:\n",
    "            speaker_tag = 1\n",
    "            for result in data['results']:\n",
    "                for word in result['alternatives'][0]['words']:\n",
    "                    # Skip \"s\" at the end of the string\n",
    "                    start_time = float(word['startTime'][:-1])\n",
    "                    end_time = float(word['endTime'][:-1])\n",
    "                    bin_voice_activity[speaker_tag] = np.where(\n",
    "                        (x_audio_signal >= start_time) & (x_audio_signal <= end_time), \n",
    "                        1, bin_voice_activity[speaker_tag])\n",
    "                    \n",
    "    # Plot raw audio signal and bin_voice_activity\n",
    "#     plt.figure(figsize=[15,6])\n",
    "    plt.figure(figsize=[25,6])\n",
    "    plt.title(audio_basename)\n",
    "    plt.plot(x_audio_signal, audio_signal, 'g-', alpha=0.3, label='audio signal')#,linewidth=2.0)\n",
    "    for speaker_tag in speaker_tags:\n",
    "        plt.plot(x_audio_signal, bin_voice_activity[speaker_tag] - speaker_tag*1.5 + 1.5, label=f'bin_voice_activity_{speaker_tag}')#,linewidth=2.0)\n",
    "#     plt.xlim(110, 135)\n",
    "    plt.ylim(-1.6, 1.6)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'./speaker_diarization_plots_google/{audio_basename}.png')\n",
    "#     plt.show()\n",
    "    \n",
    "#     break\n",
    "        \n",
    "print(f'Processed {i + 1} Google speech2text output files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
