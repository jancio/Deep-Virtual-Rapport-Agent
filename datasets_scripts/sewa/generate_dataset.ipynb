{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "# Project: Deep Virtual Rapport Agent (data preprocessing)\n",
    "#\n",
    "#     Jan Ondras (jo951030@gmail.com)\n",
    "#     Institute for Creative Technologies, University of Southern California\n",
    "#     April-October 2019\n",
    "#\n",
    "#######################################################################################################################\n",
    "# Generate segmented/sequenced dataset from sewa dataset\n",
    "#\n",
    "#     For head gestures nod and shake.\n",
    "#\n",
    "#     Run after the annotate_features.ipynb script was run.\n",
    "#     Also, perform dataset split into train/val/(test) partitions.\n",
    "#\n",
    "#     Input features: dvra_datasets/sewa/annotated_features\n",
    "#     Output dataset: dvra_datasets/sewa/segmented_datasets\n",
    "#\n",
    "#     The generated dataset was used for the development of the Head Gesture Detector.\n",
    "#######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "import numpy as np\n",
    "random_seed = 37\n",
    "np.random.seed(random_seed)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(random_seed)\n",
    "###########################################################\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Mask value (if all features for a given sample timestep are equal to MASK_VALUE, \n",
    "# then the sample timestep will be masked (skipped))\n",
    "# Cannot use MASK_VALUE=0.0, as it corresponds to no movement (derivatives are zero)\n",
    "# Cannot use MASK_VALUE=np.inf, as RandomUnderSampler cannot handle NaNs and Inf values\n",
    "MASK_VALUE = 7777777.7777777\n",
    "    \n",
    "    \n",
    "def generate_dataset(selected_features, window_size, val_size, head_gesture):\n",
    "    '''\n",
    "    Split dataset (csv files of recordings) into train/val paritions (to train final model to be used for cross-dataset prediction).\n",
    "    Also prepare test partition that contains all the data for cross-dataset testing. \n",
    "    Segment both partitions of the dataset.\n",
    "        Dataset is segmented into same-length (window_size) sequences.\n",
    "        Feature segments are pre-padded with MASK_VALUE-s and label segments with 0 (not a nod/shake/tilt).\n",
    "    For other datasets need to modify to include all available annotations (for nod, shake, tilt).\n",
    "    One output file is saved. \n",
    "    ''' \n",
    "    \n",
    "    dataset_output_filename_prefix = f'/home/ICT2000/jondras/dvra_datasets/sewa/segmented_datasets/'\n",
    "    \n",
    "    dataset_type = f'{window_size}ws_{len(selected_features)}f'\n",
    "    if not os.path.exists(dataset_output_filename_prefix):\n",
    "        os.makedirs(dataset_output_filename_prefix)\n",
    "    \n",
    "    print(f'Head gesture: {head_gesture}')\n",
    "    print(f'Window size: {window_size}')\n",
    "    n_features = len(selected_features)\n",
    "    print(f'Selected features: \\n\\t{selected_features}')\n",
    "        \n",
    "    \n",
    "    def get_segments(df):\n",
    "        '''\n",
    "        Generate segments (X (features) and Y (labels)) from the dataframe. \n",
    "        \n",
    "        Returns 2 lists of 2D arrays.\n",
    "        '''\n",
    "        \n",
    "        X = []\n",
    "        Y = []\n",
    "\n",
    "        # Pre-pad all features and labels with (window_size - 1) MASK_VALUE-s \n",
    "        padded_features = np.pad(df.values[:, :-1], ((window_size - 1, 0), (0, 0)), \n",
    "                                 mode='constant', constant_values=(MASK_VALUE, MASK_VALUE))\n",
    "        # Labels are padded with 0 mask value (indicating not a nod)\n",
    "        padded_labels   = np.pad(df.values[:, -1],  (window_size - 1, 0), \n",
    "                                 mode='constant', constant_values=(0, 0))\n",
    "        \n",
    "        assert padded_features.shape[1] == n_features\n",
    "        assert padded_labels.shape[0] == padded_features.shape[0]\n",
    "        assert len(padded_features) - window_size + 1 == len(df), 'Padding failed!'\n",
    "\n",
    "        # Slide window of length window_size over the padded features/labels\n",
    "        for i in range(len(df)):       \n",
    "            X.append( padded_features[i:i + window_size] )\n",
    "            Y.append( padded_labels[i:i + window_size] )\n",
    "\n",
    "        return X, Y\n",
    "    \n",
    "    \n",
    "    # Load the annotated feature files\n",
    "    input_annotated_features_dir = '/home/ICT2000/jondras/dvra_datasets/sewa/annotated_features'\n",
    "    input_filenames = np.array(sorted(glob.glob(input_annotated_features_dir + '/*.csv')))\n",
    "    n_subjects = len(input_filenames)\n",
    "    print(f'\\t {n_subjects} subjects/sessions')\n",
    "    \n",
    "    # Segment into train+val set\n",
    "    start_time = time.time()\n",
    "    segments = defaultdict(list)\n",
    "    for annotated_features_file in input_filenames:\n",
    "        # Take only selected features and annotation columns.\n",
    "        df = pd.read_csv(annotated_features_file)[selected_features + [head_gesture]]\n",
    "\n",
    "        # Split recording into train and val partitions\n",
    "        # Validation part starts at a random start index and has the length int(val_size * len(df))\n",
    "        # start_idx (included), end_idx (excluded)\n",
    "        val_len = int(val_size * len(df))\n",
    "        start_idx = np.random.randint(0, len(df) - val_len + 1)\n",
    "        if val_len < window_size:\n",
    "            warnings.warn(f'Validation size {val_len} is less than {window_size}!')\n",
    "\n",
    "        # Get segments from the val partition\n",
    "        X_val, Y_val = get_segments(df=df.iloc[start_idx:start_idx + val_len])\n",
    "        # Get segments from the LHS of the val partition\n",
    "        X_train_1, Y_train_1 = get_segments(df=df.iloc[0:start_idx])\n",
    "        # Get segments from the RHS of the val partition\n",
    "        X_train_2, Y_train_2 = get_segments(df=df.iloc[start_idx + val_len:len(df)])\n",
    "\n",
    "        assert len(X_val) == val_len\n",
    "        assert len(X_train_1) + len(X_train_2) == len(df) - val_len\n",
    "\n",
    "        segments['X_train'].extend(X_train_1)\n",
    "        segments['X_train'].extend(X_train_2)\n",
    "        segments['X_val'].extend(X_val)\n",
    "\n",
    "        segments['Y_train'].extend(Y_train_1)\n",
    "        segments['Y_train'].extend(Y_train_2)\n",
    "        segments['Y_val'].extend(Y_val)\n",
    "\n",
    "        # Record lengths of each batch of segments (needed for correct evaluation)\n",
    "        segments['train_len'].append((len(X_train_1), len(X_train_2)))\n",
    "        segments['val_len'].append(len(X_val))\n",
    "        \n",
    "        # Get all segments for cross-dataset testing\n",
    "        X_test, Y_test = get_segments(df=df)\n",
    "        assert len(X_test) == len(df)\n",
    "        segments['X_test'].extend(X_test)\n",
    "        segments['Y_test'].extend(Y_test)\n",
    "        segments['test_len'].append(len(X_test))\n",
    "\n",
    "    # Convert lists to numpy arrays and reshape Y to be 3D (as needed for training)\n",
    "    for key in segments.keys():\n",
    "        segments[key] = np.array(segments[key])\n",
    "        if key[0] == 'Y':\n",
    "            segments[key] = np.expand_dims(segments[key], axis=-1)               \n",
    "        print(key, segments[key].shape)\n",
    "\n",
    "    # Save train/val/test segmented data for this fold\n",
    "    segments['selected_features'] = selected_features\n",
    "    segments['WINDOW_SIZE'] = window_size\n",
    "    segments['MASK_VALUE'] = MASK_VALUE\n",
    "    np.savez(dataset_output_filename_prefix + f'sewa_{head_gesture}_{dataset_type}', **segments)\n",
    "\n",
    "    n_examples = len(segments['X_train']) + len(segments['X_val'])\n",
    "    print(f\"\\t\\t train:val = {len(segments['X_train'])}:{len(segments['X_val'])} = {len(segments['X_train'])/n_examples}:{len(segments['X_val'])/n_examples}\")\n",
    "    for partition in ['train', 'val', 'test']:\n",
    "        print(f'\\t\\t Number of {partition} examples per class: \\t{np.unique(segments[f\"Y_{partition}\"][:, -1], return_counts=True)}')        \n",
    "    print(f'\\t\\t Total time taken: {time.time() - start_time} s')\n",
    "    print('====================================================================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head gesture: nod\n",
      "Window size: 32\n",
      "Selected features: \n",
      "\t['diff_ pose_Tx', 'diff_ pose_Ty', 'diff_ pose_Tz', 'diff_ pose_Rx', 'diff_ pose_Ry', 'diff_ pose_Rz']\n",
      "\t 538 subjects/sessions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 27 is less than 32!\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 22 is less than 32!\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 31 is less than 32!\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 18 is less than 32!\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 24 is less than 32!\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 9 is less than 32!\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 13 is less than 32!\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 21 is less than 32!\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 30 is less than 32!\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 12 is less than 32!\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Validation size 20 is less than 32!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (255118, 32, 6)\n",
      "X_val (44794, 32, 6)\n",
      "Y_train (255118, 32, 1)\n",
      "Y_val (44794, 32, 1)\n",
      "train_len (538, 2)\n",
      "val_len (538,)\n",
      "X_test (299912, 32, 6)\n",
      "Y_test (299912, 32, 1)\n",
      "test_len (538,)\n",
      "\t\t train:val = 255118:44794 = 0.8506428552375364:0.14935714476246365\n",
      "\t\t Number of train examples per class: \t(array([0., 1.]), array([235133,  19985]))\n",
      "\t\t Number of val examples per class: \t(array([0., 1.]), array([41089,  3705]))\n",
      "\t\t Number of test examples per class: \t(array([0., 1.]), array([276222,  23690]))\n",
      "\t\t Total time taken: 111.05882239341736 s\n",
      "====================================================================================================\n",
      "Head gesture: shake\n",
      "Window size: 32\n",
      "Selected features: \n",
      "\t['diff_ pose_Tx', 'diff_ pose_Ty', 'diff_ pose_Tz', 'diff_ pose_Rx', 'diff_ pose_Ry', 'diff_ pose_Rz']\n",
      "\t 538 subjects/sessions\n",
      "X_train (255118, 32, 6)\n",
      "X_val (44794, 32, 6)\n",
      "Y_train (255118, 32, 1)\n",
      "Y_val (44794, 32, 1)\n",
      "train_len (538, 2)\n",
      "val_len (538,)\n",
      "X_test (299912, 32, 6)\n",
      "Y_test (299912, 32, 1)\n",
      "test_len (538,)\n",
      "\t\t train:val = 255118:44794 = 0.8506428552375364:0.14935714476246365\n",
      "\t\t Number of train examples per class: \t(array([0., 1.]), array([248965,   6153]))\n",
      "\t\t Number of val examples per class: \t(array([0., 1.]), array([43649,  1145]))\n",
      "\t\t Number of test examples per class: \t(array([0., 1.]), array([292614,   7298]))\n",
      "\t\t Total time taken: 109.47123622894287 s\n",
      "====================================================================================================\n",
      "Head gesture: nod\n",
      "Window size: 32\n",
      "Selected features: \n",
      "\t['diff_ pose_Tx', 'diff_ pose_Ty', 'diff_ pose_Tz', 'diff2_ pose_Tx', 'diff2_ pose_Ty', 'diff2_ pose_Tz', 'diff_ pose_Rx', 'diff_ pose_Ry', 'diff_ pose_Rz', 'diff2_ pose_Rx', 'diff2_ pose_Ry', 'diff2_ pose_Rz']\n",
      "\t 538 subjects/sessions\n",
      "X_train (255118, 32, 12)\n",
      "X_val (44794, 32, 12)\n",
      "Y_train (255118, 32, 1)\n",
      "Y_val (44794, 32, 1)\n",
      "train_len (538, 2)\n",
      "val_len (538,)\n",
      "X_test (299912, 32, 12)\n",
      "Y_test (299912, 32, 1)\n",
      "test_len (538,)\n",
      "\t\t train:val = 255118:44794 = 0.8506428552375364:0.14935714476246365\n",
      "\t\t Number of train examples per class: \t(array([0., 1.]), array([234727,  20391]))\n",
      "\t\t Number of val examples per class: \t(array([0., 1.]), array([41495,  3299]))\n",
      "\t\t Number of test examples per class: \t(array([0., 1.]), array([276222,  23690]))\n",
      "\t\t Total time taken: 139.50834608078003 s\n",
      "====================================================================================================\n",
      "Head gesture: shake\n",
      "Window size: 32\n",
      "Selected features: \n",
      "\t['diff_ pose_Tx', 'diff_ pose_Ty', 'diff_ pose_Tz', 'diff2_ pose_Tx', 'diff2_ pose_Ty', 'diff2_ pose_Tz', 'diff_ pose_Rx', 'diff_ pose_Ry', 'diff_ pose_Rz', 'diff2_ pose_Rx', 'diff2_ pose_Ry', 'diff2_ pose_Rz']\n",
      "\t 538 subjects/sessions\n",
      "X_train (255118, 32, 12)\n",
      "X_val (44794, 32, 12)\n",
      "Y_train (255118, 32, 1)\n",
      "Y_val (44794, 32, 1)\n",
      "train_len (538, 2)\n",
      "val_len (538,)\n",
      "X_test (299912, 32, 12)\n",
      "Y_test (299912, 32, 1)\n",
      "test_len (538,)\n",
      "\t\t train:val = 255118:44794 = 0.8506428552375364:0.14935714476246365\n",
      "\t\t Number of train examples per class: \t(array([0., 1.]), array([248497,   6621]))\n",
      "\t\t Number of val examples per class: \t(array([0., 1.]), array([44117,   677]))\n",
      "\t\t Number of test examples per class: \t(array([0., 1.]), array([292614,   7298]))\n",
      "\t\t Total time taken: 126.43889570236206 s\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "selected_features_1 = [\n",
    "    'diff_ pose_Tx', \n",
    "    'diff_ pose_Ty', \n",
    "    'diff_ pose_Tz',\n",
    "\n",
    "    'diff_ pose_Rx', \n",
    "    'diff_ pose_Ry', \n",
    "    'diff_ pose_Rz',\n",
    "]\n",
    "selected_features_2 = [\n",
    "    'diff_ pose_Tx', \n",
    "    'diff_ pose_Ty', \n",
    "    'diff_ pose_Tz',\n",
    "    \n",
    "    'diff2_ pose_Tx', \n",
    "    'diff2_ pose_Ty', \n",
    "    'diff2_ pose_Tz',\n",
    "\n",
    "    'diff_ pose_Rx', \n",
    "    'diff_ pose_Ry', \n",
    "    'diff_ pose_Rz',\n",
    "    \n",
    "    'diff2_ pose_Rx', \n",
    "    'diff2_ pose_Ry', \n",
    "    'diff2_ pose_Rz',\n",
    "]\n",
    "\n",
    "for sf in [selected_features_1, selected_features_2]:\n",
    "    for ws in [32]:\n",
    "        for hg in ['nod', 'shake']:\n",
    "            generate_dataset(selected_features=sf, window_size=ws, val_size=0.15, head_gesture=hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
