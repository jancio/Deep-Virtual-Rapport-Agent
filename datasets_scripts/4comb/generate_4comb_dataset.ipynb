{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "# Project: Deep Virtual Rapport Agent (data preprocessing)\n",
    "#\n",
    "#     Jan Ondras (jo951030@gmail.com)\n",
    "#     Institute for Creative Technologies, University of Southern California\n",
    "#     April-October 2019\n",
    "#\n",
    "#######################################################################################################################\n",
    "# Generate segmented/sequenced dataset from vra1, sewa, hatice2010, and nvb datasets\n",
    "#\n",
    "#     For all head gestures (nod, shake, tilt)\n",
    "#\n",
    "#     The annotate_features.ipynb scripts of these datasets need to be run first! \n",
    "#\n",
    "#     Single subject-independent split into train-val-test\n",
    "#\n",
    "#     Optionally perform augmentations. Sample outputs:\n",
    "#         4comb_nod_32ws_12f.npz (without augmentations)\n",
    "#         4comb_nod_32ws_12f_A1.npz (augmentation 1 applied)\n",
    "#\n",
    "#     Assumes that the features from all datasets are already resampled to same frequency and annotated.\n",
    "#\n",
    "#     Note: the 1st and 2nd order differences will have to be recalculated if augmentation is applied\n",
    "#\n",
    "#     Input features: dvra_datasets/vra1/listener_annotated_features\n",
    "#                     dvra_datasets/sewa/annotated_features\n",
    "#                     dvra_datasets/hatice2010/annotated_features\n",
    "#                     dvra_datasets/nvb/annotated_features\n",
    "#\n",
    "#     Output dataset: dvra_datasets/4comb/segmented_datasets/\n",
    "#\n",
    "#                     (print outputs from this script were also saved in \n",
    "#                      deep-virtual-rapport-agent/notes/results/log_generate_4comb_dataset.docx)\n",
    "#\n",
    "#     The generated dataset was used for the development of the Head Gesture Detector.\n",
    "#     In future, the ccdb dataset can also be included in the training data, extending the 4comb dataset to 5comb.\n",
    "#######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "import numpy as np\n",
    "random_seed = 37\n",
    "np.random.seed(random_seed)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(random_seed)\n",
    "###########################################################\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# Mask value (if all features for a given sample timestep are equal to MASK_VALUE, \n",
    "# then the sample timestep will be masked (skipped))\n",
    "# Cannot use MASK_VALUE=0.0, as it corresponds to no movement (derivatives are zero)\n",
    "# Cannot use MASK_VALUE=np.inf, as RandomUnderSampler cannot handle NaNs and Inf values\n",
    "MASK_VALUE = 7777777.7777777\n",
    "\n",
    "\n",
    "def generate_4comb_dataset(selected_features, window_size, val_size, test_size, head_gesture, \n",
    "                           augment, augment_params={}):\n",
    "    \n",
    "#     dataset_names = ['vra1', 'sewa', 'hatice2010', 'nvb']\n",
    "    \n",
    "    dataset_type = f'{window_size}ws_{len(selected_features)}f'\n",
    "    dataset_output_filename_prefix = f'/home/ICT2000/jondras/dvra_datasets/4comb/segmented_datasets/4comb_{head_gesture}_{dataset_type}'\n",
    "        \n",
    "    # Nod offsets (needed for vra1 dataset only)\n",
    "    nods_offsets_filename = f'/home/ICT2000/jondras/datasets/vra1/offsetListenerNods.txt'\n",
    "    nods_offsets = np.loadtxt(nods_offsets_filename)\n",
    "    \n",
    "    print(f'Head gesture: {head_gesture}')\n",
    "    print(f'Window size: {window_size}')\n",
    "    print(f'Val size: {val_size}\\t Test size: {test_size}')\n",
    "    print(f'Selected features: \\n\\t{selected_features}')\n",
    "    if augment:\n",
    "        print(f'Augmentation params: \\n\\t{augment_params}')\n",
    "        dataset_output_filename_prefix += f'_A{augment_params[\"augment_id\"]}'\n",
    "    print()\n",
    "        \n",
    "    start_time = time.time()\n",
    "    # Segments (and chunk lengths) of all 4 datasets\n",
    "    segments = defaultdict(list)\n",
    "        \n",
    "    def get_croppped_dataframe(annotated_features_file):\n",
    "        '''\n",
    "        Needed for vra1 dataset only\n",
    "        Ignore the beginning of the recording prior to the beep & take only selected features and annotations.\n",
    "        '''\n",
    "        \n",
    "        # Get subject ID and its offset\n",
    "        sid = annotated_features_file.split('/')[-1].split('.')[0][3:]\n",
    "        offset = nods_offsets[int(sid) - 1]\n",
    "#         print(sid, offset)\n",
    "        \n",
    "        df = pd.read_csv(annotated_features_file)\n",
    "        df = df[df[' timestamp'] >= offset][selected_features + [head_gesture]]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def get_segments(df):\n",
    "        '''\n",
    "        Generate segments (X (features) and Y (labels)) from the dataframe. \n",
    "        \n",
    "        Returns 2 lists of 2D arrays.\n",
    "        '''\n",
    "        \n",
    "        X = []\n",
    "        Y = []\n",
    "\n",
    "        # Pre-pad all features and labels with (window_size - 1) MASK_VALUE-s \n",
    "        padded_features = np.pad(df.values[:, :-1], ((window_size - 1, 0), (0, 0)), \n",
    "                                 mode='constant', constant_values=(MASK_VALUE, MASK_VALUE))\n",
    "        # Labels are padded with 0 mask value (indicating not a nod)\n",
    "        padded_labels   = np.pad(df.values[:, -1],  (window_size - 1, 0), \n",
    "                                 mode='constant', constant_values=(0, 0))\n",
    "        \n",
    "        assert padded_features.shape[1] == len(selected_features)\n",
    "        assert padded_labels.shape[0] == padded_features.shape[0]\n",
    "        assert len(padded_features) - window_size + 1 == len(df), 'Padding failed!'\n",
    "\n",
    "        # Slide window of length window_size over the padded features/labels\n",
    "        for i in range(len(df)):       \n",
    "            X.append( padded_features[i:i + window_size] )\n",
    "            Y.append( padded_labels[i:i + window_size] )\n",
    "\n",
    "        return X, Y\n",
    "    \n",
    "    def augment_df(df, augment_params):\n",
    "        # Perform augmentatations of the given dataframe (contains only selected features and annotation)\n",
    "        # Only on training dataframes!\n",
    "        \n",
    "        # Third approach: pre-defined augmentations\n",
    "        # Horizontal flip (negation) of 1st and 2nd differences of rotation features\n",
    "        # Specified by binary encodings, e.g., '101' means to flip the Rx and Rz feature types\n",
    "        augmented_dfs = []\n",
    "        for bin_augment_encoding in augment_params['horizontal_flip_bin_encodings']:\n",
    "            assert len(bin_augment_encoding) == len(augment_params['horizontal_flip_feature_types'])\n",
    "            augmented_df = df.copy()\n",
    "            for i, flip_feature in enumerate(bin_augment_encoding):\n",
    "                if flip_feature == '1':\n",
    "                    feature_name = augment_params['horizontal_flip_feature_types'][i]\n",
    "                    augmented_df['diff_' + feature_name] = -augmented_df['diff_' + feature_name]\n",
    "                    augmented_df['diff2_' + feature_name] = -augmented_df['diff2_' + feature_name]\n",
    "            augmented_dfs.append(augmented_df)\n",
    "                                                                                                \n",
    "#         # Second approach: random augmentations\n",
    "#         # Random horizontal flip (negation) of 1st and 2nd differences of features given by augment_params['horizontal_flip_feature_types'] independently\n",
    "#         # Augmentations consist of the original df and other augment_params['n_augment'] dfs\n",
    "#         # Each augmentation is encoded as a decimal/binary number\n",
    "#         # E.g. for 6 feature types: 100001 means to flip the first and last feature type\n",
    "#         augmented_dfs = []\n",
    "#         # Add original df, corresponds to decimal encoding 0\n",
    "#         augmented_dfs.append(df.copy())\n",
    "#         n_feature_types_to_augment = len(augment_params['horizontal_flip_feature_types'])\n",
    "#         # Shift by 1 since the original df (encoded as 0) is already included\n",
    "#         dec_augment_encodings = np.random.choice((2 ** n_feature_types_to_augment) - 1, \n",
    "#                                                  augment_params['n_augment'], replace=False) + 1\n",
    "#         #print(dec_augment_encodings)\n",
    "#         for dec_augment_encoding in dec_augment_encodings:\n",
    "#             augmented_df = df.copy()\n",
    "#             # Convert decimal to binary encoding and perform augmentations\n",
    "#             bin_augment_encoding = f'{dec_augment_encoding:0{n_feature_types_to_augment}b}'\n",
    "#             print(f'\\t\\tbin_augment_encoding: {bin_augment_encoding}')\n",
    "#             for i, flip_feature in enumerate(bin_augment_encoding):\n",
    "#                 #print(i, flip_feature)\n",
    "#                 if flip_feature == '1':\n",
    "#                     feature_name = augment_params['horizontal_flip_feature_types'][i]\n",
    "#                     augmented_df['diff_' + feature_name] = -augmented_df['diff_' + feature_name]\n",
    "#                     augmented_df['diff2_' + feature_name] = -augmented_df['diff2_' + feature_name]\n",
    "#             augmented_dfs.append(augmented_df)\n",
    "        \n",
    "#         # First approach: may generate duplicate augmentations\n",
    "#         augmented_dfs = []\n",
    "#         for _ in range(augment_params['n_augment']):\n",
    "#             augmented_df = df.copy()\n",
    "            \n",
    "#             # Random horizontal flip of each time-series independently\n",
    "#             for feature_name in augment_params['horizontal_flip_features']:\n",
    "#                 if np.random.uniform() < augment_params['horizontal_flip_probab']:\n",
    "#                     augmented_df[feature_name] = -augmented_df[feature_name]\n",
    "                    \n",
    "#             # Stretch / squeeze\n",
    "#             # ...\n",
    "#             # Recalculate differences\n",
    "#             # Fix annotations\n",
    "                    \n",
    "#             augmented_dfs.append(augmented_df)\n",
    "        \n",
    "        return augmented_dfs\n",
    "    \n",
    "    ######################################################################################################\n",
    "    # vra1 dataset\n",
    "    #\n",
    "    #     each recording is different subject (in total 45 subjects)\n",
    "\n",
    "    if head_gesture == 'nod':\n",
    "        \n",
    "        # Load the annotated feature files\n",
    "        input_annotated_features_dir = '/home/ICT2000/jondras/dvra_datasets/vra1/listener_annotated_features_perframe'\n",
    "        input_filenames = np.array(sorted(glob.glob(input_annotated_features_dir + '/*.csv')))\n",
    "\n",
    "        n_subjects = len(input_filenames)\n",
    "        n_test_subjects = int(n_subjects * test_size)\n",
    "        n_val_subjects = int(n_subjects * val_size)\n",
    "        n_train_subjects = n_subjects - n_val_subjects - n_test_subjects\n",
    "        # print(f'\\t {n_subjects} subjects/sessions')\n",
    "        print(f'vra1 dataset: \\n\\t {n_train_subjects} train subjects \\n\\t {n_val_subjects} val subjects \\n\\t {n_test_subjects} test subjects')\n",
    "\n",
    "        # Shuffle and split filenames\n",
    "        input_filenames = shuffle(input_filenames, random_state=random_seed)\n",
    "\n",
    "        # Split dataset recordings into train-val-test in a subject-independent manner\n",
    "        # data_split maps dataset_partition (train/val/test) to list of recordings (csv filenames)\n",
    "        data_split = dict()\n",
    "        data_split['train'] = input_filenames[:n_train_subjects]\n",
    "        data_split['val']   = input_filenames[n_train_subjects:n_train_subjects + n_val_subjects]\n",
    "        data_split['test']  = input_filenames[n_train_subjects + n_val_subjects:]\n",
    "    #     print(data_split)\n",
    "\n",
    "        # Get training, validation and testing segments\n",
    "        for dataset_partition in ['train', 'val', 'test']:\n",
    "            for annotated_features_file in data_split[dataset_partition]:\n",
    "                df = get_croppped_dataframe(annotated_features_file)\n",
    "\n",
    "                # Apply random augmentations to training dataframes\n",
    "                if augment and dataset_partition == 'train':\n",
    "                    dfs = augment_df(df, augment_params)\n",
    "                else:\n",
    "                    dfs = [df]\n",
    "\n",
    "                for df_i in dfs:\n",
    "                    X, Y = get_segments(df=df_i)\n",
    "                    assert len(X) == len(df_i)\n",
    "                    segments[f'X_{dataset_partition}'].extend(X)\n",
    "                    segments[f'Y_{dataset_partition}'].extend(Y)\n",
    "                    segments[f'{dataset_partition}_len'].append(len(X))\n",
    "\n",
    "        for key in segments.keys(): print(key, len(segments[key]))\n",
    "        print()\n",
    "        \n",
    "    ######################################################################################################\n",
    "    # sewa dataset\n",
    "    #\n",
    "    #     several recordings per subject (in total 275 subjects)\n",
    "    \n",
    "    if (head_gesture == 'nod') or (head_gesture == 'shake'):\n",
    "\n",
    "        # Load the annotated feature files \n",
    "        input_annotated_features_dir = '/home/ICT2000/jondras/dvra_datasets/sewa/annotated_features'\n",
    "        # Map subject ID to a list of its recordings\n",
    "        sid_to_filenames = defaultdict(list)\n",
    "        for annotated_features_file in sorted(glob.glob(input_annotated_features_dir + '/*.csv')):\n",
    "            sid = int(annotated_features_file.split('/')[-1].split('_')[3][1:])\n",
    "            sid_to_filenames[sid].append(annotated_features_file)\n",
    "        sids = list(sid_to_filenames.keys())\n",
    "    #     print(sid_to_filenames)\n",
    "\n",
    "        n_subjects = len(sids)\n",
    "        n_test_subjects = int(n_subjects * test_size)\n",
    "        n_val_subjects = int(n_subjects * val_size)\n",
    "        n_train_subjects = n_subjects - n_val_subjects - n_test_subjects\n",
    "        # print(f'\\t {n_subjects} subjects/sessions')\n",
    "        print(f'sewa dataset: \\n\\t {n_train_subjects} train subjects \\n\\t {n_val_subjects} val subjects \\n\\t {n_test_subjects} test subjects')\n",
    "\n",
    "        # Shuffle and split filenames by subject\n",
    "        sids = shuffle(sids, random_state=random_seed)\n",
    "    #     print(sids)\n",
    "    #     print(len(sids))\n",
    "\n",
    "        # Split dataset recordings into train-val-test in a subject-independent manner\n",
    "        # data_split maps dataset_partition (train/val/test) to list of recordings (csv filenames)\n",
    "        data_split = dict()\n",
    "        data_split['train'] = [filename for sid in sids[:n_train_subjects] for filename in sid_to_filenames[sid]]\n",
    "        data_split['val'] = [filename for sid in sids[n_train_subjects:n_train_subjects + n_val_subjects] for filename in sid_to_filenames[sid]]\n",
    "        data_split['test'] = [filename for sid in sids[n_train_subjects + n_val_subjects:] for filename in sid_to_filenames[sid]]\n",
    "    #     print(data_split)\n",
    "\n",
    "        # Get training, validation and testing segments\n",
    "        for dataset_partition in ['train', 'val', 'test']:\n",
    "            for annotated_features_file in data_split[dataset_partition]:\n",
    "                # Take only selected features and annotation columns\n",
    "                df = pd.read_csv(annotated_features_file)[selected_features + [head_gesture]]\n",
    "\n",
    "                # Apply random augmentations to training dataframes\n",
    "                if augment and dataset_partition == 'train':\n",
    "                    dfs = augment_df(df, augment_params)\n",
    "                else:\n",
    "                    dfs = [df]\n",
    "\n",
    "                for df_i in dfs:\n",
    "                    X, Y = get_segments(df=df_i)\n",
    "                    assert len(X) == len(df_i)\n",
    "                    segments[f'X_{dataset_partition}'].extend(X)\n",
    "                    segments[f'Y_{dataset_partition}'].extend(Y)\n",
    "                    segments[f'{dataset_partition}_len'].append(len(X))\n",
    "\n",
    "        for key in segments.keys(): print(key, len(segments[key]))\n",
    "        print()\n",
    "        \n",
    "    ######################################################################################################\n",
    "    # hatice2010 dataset\n",
    "    #\n",
    "    #     several recordings per subject (in total 8 (nod and shake) + 7 (other) subjects)\n",
    "    \n",
    "    if (head_gesture == 'nod') or (head_gesture == 'shake'):\n",
    "\n",
    "        subject_groups = ['nodshake', 'other']\n",
    "        sids = {\n",
    "            'nodshake': list(range(1, 9)), \n",
    "            'other':    list(range(9, 16))\n",
    "        }\n",
    "    #     print(sids)\n",
    "        # Load the annotated feature files\n",
    "        input_annotated_features_dir = '/home/ICT2000/jondras/dvra_datasets/hatice2010/annotated_features'\n",
    "        # Map subject ID to a list of its recordings\n",
    "        sid_to_filenames = defaultdict(list)\n",
    "        for annotated_features_file in sorted(glob.glob(input_annotated_features_dir + '/*.csv')):\n",
    "            sid = int(annotated_features_file.split('/')[-1].split('_')[0])\n",
    "            sid_to_filenames[sid].append(annotated_features_file)\n",
    "    #     print(sid_to_filenames)\n",
    "\n",
    "        # Split dataset recordings into train-val-test in a subject-independent manner\n",
    "        # data_split maps dataset_partition (train/val/test) to list of recordings (csv filenames)\n",
    "        data_split = defaultdict(list)\n",
    "\n",
    "        # Split each group of subjects separately\n",
    "        for subject_group in subject_groups:\n",
    "\n",
    "            n_subjects = len(sids[subject_group])\n",
    "            n_test_subjects = int(n_subjects * test_size)\n",
    "            n_val_subjects = int(n_subjects * val_size)\n",
    "            n_train_subjects = n_subjects - n_val_subjects - n_test_subjects\n",
    "            print(f'hatice2010 dataset [{subject_group}]: \\n\\t {n_train_subjects} train subjects \\n\\t {n_val_subjects} val subjects \\n\\t {n_test_subjects} test subjects')\n",
    "\n",
    "            # Shuffle and split filenames by subject\n",
    "            sids[subject_group] = shuffle(sids[subject_group], random_state=random_seed)\n",
    "    #         print(sids[subject_group])\n",
    "\n",
    "            data_split['train'].extend([filename for sid in sids[subject_group][:n_train_subjects] for filename in sid_to_filenames[sid]])\n",
    "            data_split['val'].extend([filename for sid in sids[subject_group][n_train_subjects:n_train_subjects + n_val_subjects] for filename in sid_to_filenames[sid]])\n",
    "            data_split['test'].extend([filename for sid in sids[subject_group][n_train_subjects + n_val_subjects:] for filename in sid_to_filenames[sid]])\n",
    "    #         print(data_split)\n",
    "\n",
    "            # Get training, validation and testing segments\n",
    "            for dataset_partition in ['train', 'val', 'test']:\n",
    "                for annotated_features_file in data_split[dataset_partition]:\n",
    "                    # Take only selected features and annotation columns\n",
    "                    df = pd.read_csv(annotated_features_file)[selected_features + [head_gesture]]\n",
    "\n",
    "                    # Apply random augmentations to training dataframes\n",
    "                    if augment and dataset_partition == 'train':\n",
    "                        dfs = augment_df(df, augment_params)\n",
    "                    else:\n",
    "                        dfs = [df]\n",
    "\n",
    "                    for df_i in dfs:\n",
    "                        X, Y = get_segments(df=df_i)\n",
    "                        assert len(X) == len(df_i)\n",
    "                        segments[f'X_{dataset_partition}'].extend(X)\n",
    "                        segments[f'Y_{dataset_partition}'].extend(Y)\n",
    "                        segments[f'{dataset_partition}_len'].append(len(X))\n",
    "\n",
    "        for key in segments.keys(): print(key, len(segments[key]))\n",
    "        print()\n",
    "\n",
    "    ######################################################################################################\n",
    "    # nvb dataset\n",
    "    #\n",
    "    #     each recording is different subject (in total 38 subjects)\n",
    "    \n",
    "    if (head_gesture == 'nod') or (head_gesture == 'shake') or (head_gesture == 'tilt'):\n",
    "\n",
    "        # Load the annotated feature files\n",
    "        input_annotated_features_dir = '/home/ICT2000/jondras/dvra_datasets/nvb/annotated_features'\n",
    "        input_filenames = np.array(sorted(glob.glob(input_annotated_features_dir + '/*.csv')))\n",
    "\n",
    "        n_subjects = len(input_filenames)\n",
    "        n_test_subjects = int(n_subjects * test_size)\n",
    "        n_val_subjects = int(n_subjects * val_size)\n",
    "        n_train_subjects = n_subjects - n_val_subjects - n_test_subjects\n",
    "        # print(f'\\t {n_subjects} subjects/sessions')\n",
    "        print(f'nvb dataset: \\n\\t {n_train_subjects} train subjects \\n\\t {n_val_subjects} val subjects \\n\\t {n_test_subjects} test subjects')\n",
    "\n",
    "        # Shuffle and split filenames\n",
    "        input_filenames = shuffle(input_filenames, random_state=random_seed)\n",
    "\n",
    "        # Split dataset recordings into train-val-test in a subject-independent manner\n",
    "        # data_split maps dataset_partition (train/val/test) to list of recordings (csv filenames)\n",
    "        data_split = dict()\n",
    "        data_split['train'] = input_filenames[:n_train_subjects]\n",
    "        data_split['val']   = input_filenames[n_train_subjects:n_train_subjects + n_val_subjects]\n",
    "        data_split['test']  = input_filenames[n_train_subjects + n_val_subjects:]\n",
    "    #     print(data_split)\n",
    "\n",
    "        # Get training, validation and testing segments\n",
    "        for dataset_partition in ['train', 'val', 'test']:\n",
    "            for annotated_features_file in data_split[dataset_partition]:\n",
    "                # Take only selected features and annotation columns\n",
    "                df = pd.read_csv(annotated_features_file)[selected_features + [head_gesture]]\n",
    "\n",
    "                # Apply random augmentations to training dataframes\n",
    "                if augment and dataset_partition == 'train':\n",
    "                    dfs = augment_df(df, augment_params)\n",
    "                else:\n",
    "                    dfs = [df]\n",
    "\n",
    "                for df_i in dfs:\n",
    "                    X, Y = get_segments(df=df_i)\n",
    "                    assert len(X) == len(df_i)\n",
    "                    segments[f'X_{dataset_partition}'].extend(X)\n",
    "                    segments[f'Y_{dataset_partition}'].extend(Y)\n",
    "                    segments[f'{dataset_partition}_len'].append(len(X))\n",
    "\n",
    "        for key in segments.keys(): print(key, len(segments[key]))\n",
    "        print()\n",
    "        \n",
    "    ######################################################################################################\n",
    "\n",
    "    # Convert lists to numpy arrays and reshape Y to be 3D (as needed for training)\n",
    "    for key in segments.keys():\n",
    "        segments[key] = np.array(segments[key])\n",
    "        if key[0] == 'Y':\n",
    "            segments[key] = np.expand_dims(segments[key], axis=-1)               \n",
    "        print(key, segments[key].shape)\n",
    "\n",
    "    # Save train/val/test segmented data for this fold\n",
    "    segments['selected_features'] = selected_features\n",
    "    segments['WINDOW_SIZE'] = window_size\n",
    "    segments['MASK_VALUE'] = MASK_VALUE\n",
    "    segments['val_size'] = val_size\n",
    "    segments['test_size'] = test_size\n",
    "    segments['head_gesture'] = head_gesture\n",
    "    segments['augment'] = augment\n",
    "    segments['augment_params'] = augment_params\n",
    "    np.savez(dataset_output_filename_prefix, **segments)\n",
    "\n",
    "    n_examples = len(segments['X_train']) + len(segments['X_val']) + len(segments['X_test'])\n",
    "    print(f\"\\t\\t train:val:test = {len(segments['X_train'])}:{len(segments['X_val'])}:{len(segments['X_test'])} = {len(segments['X_train'])/n_examples}:{len(segments['X_val'])/n_examples}:{len(segments['X_test'])/n_examples}\")\n",
    "    for partition in ['train', 'val', 'test']:\n",
    "        print(f'\\t\\t Number of {partition} examples per class: \\t{np.unique(segments[f\"Y_{partition}\"][:, -1], return_counts=True)}')        \n",
    "    print(f'\\t\\t Total time taken: {time.time() - start_time} s')\n",
    "    print('====================================================================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head gesture: nod\n",
      "Window size: 32\n",
      "Val size: 0.15\t Test size: 0.15\n",
      "Selected features: \n",
      "\t['diff_ pose_Tx', 'diff_ pose_Ty', 'diff_ pose_Tz', 'diff2_ pose_Tx', 'diff2_ pose_Ty', 'diff2_ pose_Tz', 'diff_ pose_Rx', 'diff_ pose_Ry', 'diff_ pose_Rz', 'diff2_ pose_Rx', 'diff2_ pose_Ry', 'diff2_ pose_Rz']\n",
      "\n",
      "vra1 dataset: \n",
      "\t 33 train subjects \n",
      "\t 6 val subjects \n",
      "\t 6 test subjects\n",
      "X_train 134112\n",
      "Y_train 134112\n",
      "train_len 33\n",
      "X_val 25857\n",
      "Y_val 25857\n",
      "val_len 6\n",
      "X_test 24784\n",
      "Y_test 24784\n",
      "test_len 6\n",
      "\n",
      "sewa dataset: \n",
      "\t 193 train subjects \n",
      "\t 41 val subjects \n",
      "\t 41 test subjects\n",
      "X_train 346441\n",
      "Y_train 346441\n",
      "train_len 413\n",
      "X_val 63623\n",
      "Y_val 63623\n",
      "val_len 81\n",
      "X_test 74601\n",
      "Y_test 74601\n",
      "test_len 89\n",
      "\n",
      "hatice2010 dataset [nodshake]: \n",
      "\t 6 train subjects \n",
      "\t 1 val subjects \n",
      "\t 1 test subjects\n",
      "hatice2010 dataset [other]: \n",
      "\t 5 train subjects \n",
      "\t 1 val subjects \n",
      "\t 1 test subjects\n",
      "X_train 365648\n",
      "Y_train 365648\n",
      "train_len 864\n",
      "X_val 64549\n",
      "Y_val 64549\n",
      "val_len 109\n",
      "X_test 77327\n",
      "Y_test 77327\n",
      "test_len 151\n",
      "\n",
      "nvb dataset: \n",
      "\t 28 train subjects \n",
      "\t 5 val subjects \n",
      "\t 5 test subjects\n",
      "X_train 546964\n",
      "Y_train 546964\n",
      "train_len 892\n",
      "X_val 85629\n",
      "Y_val 85629\n",
      "val_len 114\n",
      "X_test 102945\n",
      "Y_test 102945\n",
      "test_len 156\n",
      "\n",
      "X_train (546964, 32, 12)\n",
      "Y_train (546964, 32, 1)\n",
      "train_len (892,)\n",
      "X_val (85629, 32, 12)\n",
      "Y_val (85629, 32, 1)\n",
      "val_len (114,)\n",
      "X_test (102945, 32, 12)\n",
      "Y_test (102945, 32, 1)\n",
      "test_len (156,)\n",
      "\t\t train:val = 546964:85629:102945 = 0.7436243946607789:0.1164168268668648:0.1399587784723563\n",
      "\t\t Number of train examples per class: \t(array([0., 1.]), array([489312,  57652]))\n",
      "\t\t Number of val examples per class: \t(array([0., 1.]), array([78291,  7338]))\n",
      "\t\t Number of test examples per class: \t(array([0., 1.]), array([93707,  9238]))\n",
      "\t\t Total time taken: 256.4142873287201 s\n",
      "====================================================================================================\n",
      "Head gesture: shake\n",
      "Window size: 32\n",
      "Val size: 0.15\t Test size: 0.15\n",
      "Selected features: \n",
      "\t['diff_ pose_Tx', 'diff_ pose_Ty', 'diff_ pose_Tz', 'diff2_ pose_Tx', 'diff2_ pose_Ty', 'diff2_ pose_Tz', 'diff_ pose_Rx', 'diff_ pose_Ry', 'diff_ pose_Rz', 'diff2_ pose_Rx', 'diff2_ pose_Ry', 'diff2_ pose_Rz']\n",
      "\n",
      "sewa dataset: \n",
      "\t 193 train subjects \n",
      "\t 41 val subjects \n",
      "\t 41 test subjects\n",
      "X_train 212329\n",
      "Y_train 212329\n",
      "train_len 380\n",
      "X_val 37766\n",
      "Y_val 37766\n",
      "val_len 75\n",
      "X_test 49817\n",
      "Y_test 49817\n",
      "test_len 83\n",
      "\n",
      "hatice2010 dataset [nodshake]: \n",
      "\t 6 train subjects \n",
      "\t 1 val subjects \n",
      "\t 1 test subjects\n",
      "hatice2010 dataset [other]: \n",
      "\t 5 train subjects \n",
      "\t 1 val subjects \n",
      "\t 1 test subjects\n",
      "X_train 231536\n",
      "Y_train 231536\n",
      "train_len 831\n",
      "X_val 38692\n",
      "Y_val 38692\n",
      "val_len 103\n",
      "X_test 52543\n",
      "Y_test 52543\n",
      "test_len 145\n",
      "\n",
      "nvb dataset: \n",
      "\t 28 train subjects \n",
      "\t 5 val subjects \n",
      "\t 5 test subjects\n",
      "X_train 412852\n",
      "Y_train 412852\n",
      "train_len 859\n",
      "X_val 59772\n",
      "Y_val 59772\n",
      "val_len 108\n",
      "X_test 78161\n",
      "Y_test 78161\n",
      "test_len 150\n",
      "\n",
      "X_train (412852, 32, 12)\n",
      "Y_train (412852, 32, 1)\n",
      "train_len (859,)\n",
      "X_val (59772, 32, 12)\n",
      "Y_val (59772, 32, 1)\n",
      "val_len (108,)\n",
      "X_test (78161, 32, 12)\n",
      "Y_test (78161, 32, 1)\n",
      "test_len (150,)\n",
      "\t\t train:val = 412852:59772:78161 = 0.7495701589549462:0.10852147389634793:0.14190836714870594\n",
      "\t\t Number of train examples per class: \t(array([0., 1.]), array([390021,  22831]))\n",
      "\t\t Number of val examples per class: \t(array([0., 1.]), array([58287,  1485]))\n",
      "\t\t Number of test examples per class: \t(array([0., 1.]), array([72484,  5677]))\n",
      "\t\t Total time taken: 189.57718133926392 s\n",
      "====================================================================================================\n",
      "Head gesture: tilt\n",
      "Window size: 32\n",
      "Val size: 0.15\t Test size: 0.15\n",
      "Selected features: \n",
      "\t['diff_ pose_Tx', 'diff_ pose_Ty', 'diff_ pose_Tz', 'diff2_ pose_Tx', 'diff2_ pose_Ty', 'diff2_ pose_Tz', 'diff_ pose_Rx', 'diff_ pose_Ry', 'diff_ pose_Rz', 'diff2_ pose_Rx', 'diff2_ pose_Ry', 'diff2_ pose_Rz']\n",
      "\n",
      "nvb dataset: \n",
      "\t 28 train subjects \n",
      "\t 5 val subjects \n",
      "\t 5 test subjects\n",
      "X_train 181316\n",
      "Y_train 181316\n",
      "train_len 28\n",
      "X_val 21080\n",
      "Y_val 21080\n",
      "val_len 5\n",
      "X_test 25618\n",
      "Y_test 25618\n",
      "test_len 5\n",
      "\n",
      "X_train (181316, 32, 12)\n",
      "Y_train (181316, 32, 1)\n",
      "train_len (28,)\n",
      "X_val (21080, 32, 12)\n",
      "Y_val (21080, 32, 1)\n",
      "val_len (5,)\n",
      "X_test (25618, 32, 12)\n",
      "Y_test (25618, 32, 1)\n",
      "test_len (5,)\n",
      "\t\t train:val = 181316:21080:25618 = 0.7951967861622532:0.09245046356802653:0.11235275026972028\n",
      "\t\t Number of train examples per class: \t(array([0., 1.]), array([172356,   8960]))\n",
      "\t\t Number of val examples per class: \t(array([0., 1.]), array([20264,   816]))\n",
      "\t\t Number of test examples per class: \t(array([0., 1.]), array([24584,  1034]))\n",
      "\t\t Total time taken: 41.85125756263733 s\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "# Without augmentations\n",
    "#######################################\n",
    "\n",
    "# selected_features_1 = [\n",
    "#     'diff_ pose_Tx', \n",
    "#     'diff_ pose_Ty', \n",
    "#     'diff_ pose_Tz',\n",
    "\n",
    "#     'diff_ pose_Rx', \n",
    "#     'diff_ pose_Ry', \n",
    "#     'diff_ pose_Rz',\n",
    "# ]\n",
    "selected_features_2 = [\n",
    "    'diff_ pose_Tx', \n",
    "    'diff_ pose_Ty', \n",
    "    'diff_ pose_Tz',\n",
    "    \n",
    "    'diff2_ pose_Tx', \n",
    "    'diff2_ pose_Ty', \n",
    "    'diff2_ pose_Tz',\n",
    "\n",
    "    'diff_ pose_Rx', \n",
    "    'diff_ pose_Ry', \n",
    "    'diff_ pose_Rz',\n",
    "    \n",
    "    'diff2_ pose_Rx', \n",
    "    'diff2_ pose_Ry', \n",
    "    'diff2_ pose_Rz',\n",
    "]\n",
    "\n",
    "for sf in [selected_features_2]:\n",
    "    for ws in [32]:\n",
    "        for hg in ['nod', 'shake', 'tilt']:\n",
    "            generate_4comb_dataset(selected_features=sf, window_size=ws, val_size=0.15, test_size=0.15, \n",
    "                                   head_gesture=hg, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head gesture: nod\n",
      "Window size: 32\n",
      "Val size: 0.15\t Test size: 0.15\n",
      "Selected features: \n",
      "\t['diff_ pose_Tx', 'diff_ pose_Ty', 'diff_ pose_Tz', 'diff2_ pose_Tx', 'diff2_ pose_Ty', 'diff2_ pose_Tz', 'diff_ pose_Rx', 'diff_ pose_Ry', 'diff_ pose_Rz', 'diff2_ pose_Rx', 'diff2_ pose_Ry', 'diff2_ pose_Rz']\n",
      "Augmentation params: \n",
      "\t{'augment_id': 1, 'horizontal_flip_feature_types': [' pose_Rx', ' pose_Ry', ' pose_Rz'], 'horizontal_flip_bin_encodings': ['000', '010', '100', '110', '001', '011', '101', '111']}\n",
      "\n",
      "vra1 dataset: \n",
      "\t 33 train subjects \n",
      "\t 6 val subjects \n",
      "\t 6 test subjects\n",
      "X_train 1072896\n",
      "Y_train 1072896\n",
      "train_len 264\n",
      "X_val 25857\n",
      "Y_val 25857\n",
      "val_len 6\n",
      "X_test 24784\n",
      "Y_test 24784\n",
      "test_len 6\n",
      "\n",
      "sewa dataset: \n",
      "\t 193 train subjects \n",
      "\t 41 val subjects \n",
      "\t 41 test subjects\n",
      "X_train 2771528\n",
      "Y_train 2771528\n",
      "train_len 3304\n",
      "X_val 63623\n",
      "Y_val 63623\n",
      "val_len 81\n",
      "X_test 74601\n",
      "Y_test 74601\n",
      "test_len 89\n",
      "\n",
      "hatice2010 dataset [nodshake]: \n",
      "\t 6 train subjects \n",
      "\t 1 val subjects \n",
      "\t 1 test subjects\n",
      "hatice2010 dataset [other]: \n",
      "\t 5 train subjects \n",
      "\t 1 val subjects \n",
      "\t 1 test subjects\n",
      "X_train 2925184\n",
      "Y_train 2925184\n",
      "train_len 6912\n",
      "X_val 64549\n",
      "Y_val 64549\n",
      "val_len 109\n",
      "X_test 77327\n",
      "Y_test 77327\n",
      "test_len 151\n",
      "\n",
      "nvb dataset: \n",
      "\t 28 train subjects \n",
      "\t 5 val subjects \n",
      "\t 5 test subjects\n",
      "X_train 4375712\n",
      "Y_train 4375712\n",
      "train_len 7136\n",
      "X_val 85629\n",
      "Y_val 85629\n",
      "val_len 114\n",
      "X_test 102945\n",
      "Y_test 102945\n",
      "test_len 156\n",
      "\n",
      "X_train (4375712, 32, 12)\n",
      "Y_train (4375712, 32, 1)\n",
      "train_len (7136,)\n",
      "X_val (85629, 32, 12)\n",
      "Y_val (85629, 32, 1)\n",
      "val_len (114,)\n",
      "X_test (102945, 32, 12)\n",
      "Y_test (102945, 32, 1)\n",
      "test_len (156,)\n",
      "\t\t train:val:test = 4375712:85629:102945 = 0.9586848852153437:0.018760656102619337:0.022554458682037017\n",
      "\t\t Number of train examples per class: \t(array([0., 1.]), array([3914496,  461216]))\n",
      "\t\t Number of val examples per class: \t(array([0., 1.]), array([78291,  7338]))\n",
      "\t\t Number of test examples per class: \t(array([0., 1.]), array([93707,  9238]))\n",
      "\t\t Total time taken: 1826.8670070171356 s\n",
      "====================================================================================================\n",
      "Head gesture: shake\n",
      "Window size: 32\n",
      "Val size: 0.15\t Test size: 0.15\n",
      "Selected features: \n",
      "\t['diff_ pose_Tx', 'diff_ pose_Ty', 'diff_ pose_Tz', 'diff2_ pose_Tx', 'diff2_ pose_Ty', 'diff2_ pose_Tz', 'diff_ pose_Rx', 'diff_ pose_Ry', 'diff_ pose_Rz', 'diff2_ pose_Rx', 'diff2_ pose_Ry', 'diff2_ pose_Rz']\n",
      "Augmentation params: \n",
      "\t{'augment_id': 1, 'horizontal_flip_feature_types': [' pose_Rx', ' pose_Ry', ' pose_Rz'], 'horizontal_flip_bin_encodings': ['000', '010', '100', '110', '001', '011', '101', '111']}\n",
      "\n",
      "sewa dataset: \n",
      "\t 193 train subjects \n",
      "\t 41 val subjects \n",
      "\t 41 test subjects\n",
      "X_train 1698632\n",
      "Y_train 1698632\n",
      "train_len 3040\n",
      "X_val 37766\n",
      "Y_val 37766\n",
      "val_len 75\n",
      "X_test 49817\n",
      "Y_test 49817\n",
      "test_len 83\n",
      "\n",
      "hatice2010 dataset [nodshake]: \n",
      "\t 6 train subjects \n",
      "\t 1 val subjects \n",
      "\t 1 test subjects\n",
      "hatice2010 dataset [other]: \n",
      "\t 5 train subjects \n",
      "\t 1 val subjects \n",
      "\t 1 test subjects\n",
      "X_train 1852288\n",
      "Y_train 1852288\n",
      "train_len 6648\n",
      "X_val 38692\n",
      "Y_val 38692\n",
      "val_len 103\n",
      "X_test 52543\n",
      "Y_test 52543\n",
      "test_len 145\n",
      "\n",
      "nvb dataset: \n",
      "\t 28 train subjects \n",
      "\t 5 val subjects \n",
      "\t 5 test subjects\n",
      "X_train 3302816\n",
      "Y_train 3302816\n",
      "train_len 6872\n",
      "X_val 59772\n",
      "Y_val 59772\n",
      "val_len 108\n",
      "X_test 78161\n",
      "Y_test 78161\n",
      "test_len 150\n",
      "\n",
      "X_train (3302816, 32, 12)\n",
      "Y_train (3302816, 32, 1)\n",
      "train_len (6872,)\n",
      "X_val (59772, 32, 12)\n",
      "Y_val (59772, 32, 1)\n",
      "val_len (108,)\n",
      "X_test (78161, 32, 12)\n",
      "Y_test (78161, 32, 1)\n",
      "test_len (150,)\n",
      "\t\t train:val:test = 3302816:59772:78161 = 0.9599119261532881:0.01737179898911545:0.022716274857596412\n",
      "\t\t Number of train examples per class: \t(array([0., 1.]), array([3120168,  182648]))\n",
      "\t\t Number of val examples per class: \t(array([0., 1.]), array([58287,  1485]))\n",
      "\t\t Number of test examples per class: \t(array([0., 1.]), array([72484,  5677]))\n",
      "\t\t Total time taken: 1483.7619051933289 s\n",
      "====================================================================================================\n",
      "Head gesture: tilt\n",
      "Window size: 32\n",
      "Val size: 0.15\t Test size: 0.15\n",
      "Selected features: \n",
      "\t['diff_ pose_Tx', 'diff_ pose_Ty', 'diff_ pose_Tz', 'diff2_ pose_Tx', 'diff2_ pose_Ty', 'diff2_ pose_Tz', 'diff_ pose_Rx', 'diff_ pose_Ry', 'diff_ pose_Rz', 'diff2_ pose_Rx', 'diff2_ pose_Ry', 'diff2_ pose_Rz']\n",
      "Augmentation params: \n",
      "\t{'augment_id': 1, 'horizontal_flip_feature_types': [' pose_Rx', ' pose_Ry', ' pose_Rz'], 'horizontal_flip_bin_encodings': ['000', '010', '100', '110', '001', '011', '101', '111']}\n",
      "\n",
      "nvb dataset: \n",
      "\t 28 train subjects \n",
      "\t 5 val subjects \n",
      "\t 5 test subjects\n",
      "X_train 1450528\n",
      "Y_train 1450528\n",
      "train_len 224\n",
      "X_val 21080\n",
      "Y_val 21080\n",
      "val_len 5\n",
      "X_test 25618\n",
      "Y_test 25618\n",
      "test_len 5\n",
      "\n",
      "X_train (1450528, 32, 12)\n",
      "Y_train (1450528, 32, 1)\n",
      "train_len (224,)\n",
      "X_val (21080, 32, 12)\n",
      "Y_val (21080, 32, 1)\n",
      "val_len (5,)\n",
      "X_test (25618, 32, 12)\n",
      "Y_test (25618, 32, 1)\n",
      "test_len (5,)\n",
      "\t\t train:val:test = 1450528:21080:25618 = 0.9688103198849072:0.01407937078303476:0.017110309332058087\n",
      "\t\t Number of train examples per class: \t(array([0., 1.]), array([1378848,   71680]))\n",
      "\t\t Number of val examples per class: \t(array([0., 1.]), array([20264,   816]))\n",
      "\t\t Number of test examples per class: \t(array([0., 1.]), array([24584,  1034]))\n",
      "\t\t Total time taken: 126.89953947067261 s\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "# Generate augmented dataset\n",
    "#######################################\n",
    "\n",
    "# selected_features_1 = [\n",
    "#     'diff_ pose_Tx', \n",
    "#     'diff_ pose_Ty', \n",
    "#     'diff_ pose_Tz',\n",
    "\n",
    "#     'diff_ pose_Rx', \n",
    "#     'diff_ pose_Ry', \n",
    "#     'diff_ pose_Rz',\n",
    "# ]\n",
    "selected_features_2 = [\n",
    "    'diff_ pose_Tx', \n",
    "    'diff_ pose_Ty', \n",
    "    'diff_ pose_Tz',\n",
    "    \n",
    "    'diff2_ pose_Tx', \n",
    "    'diff2_ pose_Ty', \n",
    "    'diff2_ pose_Tz',\n",
    "\n",
    "    'diff_ pose_Rx', \n",
    "    'diff_ pose_Ry', \n",
    "    'diff_ pose_Rz',\n",
    "    \n",
    "    'diff2_ pose_Rx', \n",
    "    'diff2_ pose_Ry', \n",
    "    'diff2_ pose_Rz',\n",
    "]\n",
    "\n",
    "# Augmentation parameters\n",
    "augment_params = {\n",
    "    # Third approach\n",
    "    'augment_id': 1,\n",
    "    'horizontal_flip_feature_types': [\n",
    "        ' pose_Rx', \n",
    "        ' pose_Ry', \n",
    "        ' pose_Rz',\n",
    "    ],\n",
    "    'horizontal_flip_bin_encodings': [\n",
    "        '000',\n",
    "        '010',\n",
    "        '100',\n",
    "        '110',\n",
    "        '001',\n",
    "        '011',\n",
    "        '101', \n",
    "        '111'\n",
    "    ]\n",
    "    # Second approach\n",
    "#     'augment_id': 1,\n",
    "#     'n_augment': 6, \n",
    "#     'horizontal_flip_feature_types': [\n",
    "#         ' pose_Tx', \n",
    "#         ' pose_Ty', \n",
    "#         ' pose_Tz',\n",
    "#         ' pose_Rx', \n",
    "#         ' pose_Ry', \n",
    "#         ' pose_Rz',\n",
    "#     ]\n",
    "    # First approach\n",
    "#     'horizontal_flip_features': selected_features_2, \n",
    "#     'horizontal_flip_probab': 0.5\n",
    "}\n",
    "\n",
    "for sf in [selected_features_2]:\n",
    "    for ws in [32]:\n",
    "        for hg in ['nod', 'shake', 'tilt']:\n",
    "            generate_4comb_dataset(selected_features=sf, window_size=ws, val_size=0.15, test_size=0.15, \n",
    "                                   head_gesture=hg, augment=True, augment_params=augment_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
