{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/ICT2000/jondras/anaconda3/envs/dvra/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46808, 16, 6) (46808,)\n",
      "Train examples per class: (array([0, 1]), array([17553, 17553]))\n",
      "Test examples per class: (array([0, 1]), array([5851, 5851]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import GRU, LSTM, CuDNNGRU, CuDNNLSTM, Activation, LSTMCell, GRUCell\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "random_seed = 37\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load dataset\n",
    "PAST_WINDOW_SIZE = 16\n",
    "FUTURE_WINDOW_SIZE = 0\n",
    "N_FEATURES = 6\n",
    "seq_len = PAST_WINDOW_SIZE + FUTURE_WINDOW_SIZE\n",
    "dataset_filename = f'/home/ICT2000/jondras/datasets/vra1/dataset_{PAST_WINDOW_SIZE}_{FUTURE_WINDOW_SIZE}_{N_FEATURES}.npz'\n",
    "data = np.load(dataset_filename)\n",
    "X, y = data['X'], data['y']\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Split into train and test partitions\n",
    "test_size = 0.25\n",
    "\n",
    "# Not stratified split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed, shuffle=False)\n",
    "# print(f'Train examples per class: {np.unique(y_train, return_counts=True)}')\n",
    "# print(f'Test examples per class: {np.unique(y_test, return_counts=True)}')\n",
    "# Train examples per class: (array([0, 1]), array([17621, 17485]))\n",
    "# Test examples per class: (array([0, 1]), array([5783, 5919]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_seed, stratify=y)\n",
    "print(f'Train examples per class: {np.unique(y_train, return_counts=True)}')\n",
    "print(f'Test examples per class: {np.unique(y_test, return_counts=True)}')\n",
    "# Train examples per class: (array([0, 1]), array([17553, 17553]))\n",
    "# Test examples per class: (array([0, 1]), array([5851, 5851]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ./checkpoints/16_0_6/m_0030_0.5056_0.4978.hdf5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 16, 20)            1620      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 1)                 66        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,686\n",
      "Trainable params: 1,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "from keras.models import load_model\n",
    "\n",
    "test_model_name = './checkpoints/16_0_6/m_0773_0.4011_0.4156.hdf5'\n",
    "test_model_name = './checkpoints/16_0_6/m_0030_0.5056_0.4978.hdf5'\n",
    "\n",
    "\n",
    "model = load_model(test_model_name)\n",
    "print(f'Loading model {test_model_name}')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11702/11702 [==============================] - 10s 829us/step\n",
      "Accuracy: 81.15%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11702/11702 [==============================] - 12s 992us/step\n",
      "Accuracy: 89.68%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
