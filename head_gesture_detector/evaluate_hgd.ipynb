{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "# Project: Deep Virtual Rapport Agent (head gesture detector)\n",
    "#\n",
    "#     Jan Ondras (jo951030@gmail.com)\n",
    "#     Institute for Creative Technologies, University of Southern California\n",
    "#     April-October 2019\n",
    "#\n",
    "#######################################################################################################################\n",
    "#\n",
    "#     Test each model trained on one of the vra1, hatice2010, sewa, and nvb datasets on each of these datasets\n",
    "#     (cross-dataset evaluation)\n",
    "#\n",
    "#     So far, 4 x 3 = 12 nod only cross-dataset tests were performed. \n",
    "#\n",
    "#######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "import numpy as np\n",
    "random_seed = 37\n",
    "np.random.seed(random_seed)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(random_seed)\n",
    "###########################################################\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "# from keras_tqdm import TQDMNotebookCallback\n",
    "from utils import load_train_history, save_train_history, plot_loss_history, arch_to_str, evaluate_custom_metrics\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "import glob\n",
    "import time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ICT2000/jondras/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ICT2000/jondras/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ICT2000/jondras/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Loading model:\n",
      "\thatice2010_nod_32ws_12f_16u.hdf5 \t #params: 1409\n",
      "\n",
      "\tTesting on vra1\n",
      "\t\t[last] bacc: \t\t 0.6177\n",
      "\t\t[last] f1: \t\t 0.3651\n",
      "\t\t[last] precision: \t\t 0.6260\n",
      "\t\t[last] recall: \t\t 0.2577\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.6403\n",
      "\t\t[majority] f1: \t\t 0.4189\n",
      "\t\t[majority] precision: \t\t 0.6952\n",
      "\t\t[majority] recall: \t\t 0.2997\n",
      "\n",
      "\n",
      "\tTesting on sewa\n",
      "\t\t[last] bacc: \t\t 0.6470\n",
      "\t\t[last] f1: \t\t 0.2664\n",
      "\t\t[last] precision: \t\t 0.1857\n",
      "\t\t[last] recall: \t\t 0.4711\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.6582\n",
      "\t\t[majority] f1: \t\t 0.2744\n",
      "\t\t[majority] precision: \t\t 0.1890\n",
      "\t\t[majority] recall: \t\t 0.5007\n",
      "\n",
      "\n",
      "\tTesting on hatice2010\n",
      "\t\t[last] bacc: \t\t 0.9322\n",
      "\t\t[last] f1: \t\t 0.9256\n",
      "\t\t[last] precision: \t\t 0.9599\n",
      "\t\t[last] recall: \t\t 0.8936\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.9309\n",
      "\t\t[majority] f1: \t\t 0.9240\n",
      "\t\t[majority] precision: \t\t 0.9571\n",
      "\t\t[majority] recall: \t\t 0.8931\n",
      "\n",
      "\n",
      "\tTesting on nvb\n",
      "\t\t[last] bacc: \t\t 0.6748\n",
      "\t\t[last] f1: \t\t 0.2998\n",
      "\t\t[last] precision: \t\t 0.2206\n",
      "\t\t[last] recall: \t\t 0.4680\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.7190\n",
      "\t\t[majority] f1: \t\t 0.3477\n",
      "\t\t[majority] precision: \t\t 0.2532\n",
      "\t\t[majority] recall: \t\t 0.5552\n",
      "\n",
      "\n",
      "\t\t Total time taken: 28.43256711959839 s\n",
      "\n",
      "Loading model:\n",
      "\tnvb_nod_32ws_12f_16u.hdf5 \t #params: 1409\n",
      "\n",
      "\tTesting on vra1\n",
      "\t\t[last] bacc: \t\t 0.7240\n",
      "\t\t[last] f1: \t\t 0.5487\n",
      "\t\t[last] precision: \t\t 0.6206\n",
      "\t\t[last] recall: \t\t 0.4917\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.7211\n",
      "\t\t[majority] f1: \t\t 0.5468\n",
      "\t\t[majority] precision: \t\t 0.6294\n",
      "\t\t[majority] recall: \t\t 0.4834\n",
      "\n",
      "\n",
      "\tTesting on sewa\n",
      "\t\t[last] bacc: \t\t 0.7390\n",
      "\t\t[last] f1: \t\t 0.3205\n",
      "\t\t[last] precision: \t\t 0.2068\n",
      "\t\t[last] recall: \t\t 0.7123\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.7310\n",
      "\t\t[majority] f1: \t\t 0.3123\n",
      "\t\t[majority] precision: \t\t 0.2009\n",
      "\t\t[majority] recall: \t\t 0.7014\n",
      "\n",
      "\n",
      "\tTesting on hatice2010\n",
      "\t\t[last] bacc: \t\t 0.8579\n",
      "\t\t[last] f1: \t\t 0.8426\n",
      "\t\t[last] precision: \t\t 0.8003\n",
      "\t\t[last] recall: \t\t 0.8896\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.8601\n",
      "\t\t[majority] f1: \t\t 0.8447\n",
      "\t\t[majority] precision: \t\t 0.8059\n",
      "\t\t[majority] recall: \t\t 0.8874\n",
      "\n",
      "\n",
      "\tTesting on nvb\n",
      "\t\t[last] bacc: \t\t 0.8326\n",
      "\t\t[last] f1: \t\t 0.3988\n",
      "\t\t[last] precision: \t\t 0.2622\n",
      "\t\t[last] recall: \t\t 0.8329\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.8304\n",
      "\t\t[majority] f1: \t\t 0.4014\n",
      "\t\t[majority] precision: \t\t 0.2653\n",
      "\t\t[majority] recall: \t\t 0.8242\n",
      "\n",
      "\n",
      "\t\t Total time taken: 54.51887845993042 s\n",
      "\n",
      "Loading model:\n",
      "\tsewa_nod_32ws_12f_16u.hdf5 \t #params: 1409\n",
      "\n",
      "\tTesting on vra1\n",
      "\t\t[last] bacc: \t\t 0.7626\n",
      "\t\t[last] f1: \t\t 0.5731\n",
      "\t\t[last] precision: \t\t 0.5528\n",
      "\t\t[last] recall: \t\t 0.5949\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.7538\n",
      "\t\t[majority] f1: \t\t 0.5987\n",
      "\t\t[majority] precision: \t\t 0.6586\n",
      "\t\t[majority] recall: \t\t 0.5488\n",
      "\n",
      "\n",
      "\tTesting on sewa\n",
      "\t\t[last] bacc: \t\t 0.8427\n",
      "\t\t[last] f1: \t\t 0.4275\n",
      "\t\t[last] precision: \t\t 0.2828\n",
      "\t\t[last] recall: \t\t 0.8758\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.8251\n",
      "\t\t[majority] f1: \t\t 0.4287\n",
      "\t\t[majority] precision: \t\t 0.2898\n",
      "\t\t[majority] recall: \t\t 0.8233\n",
      "\n",
      "\n",
      "\tTesting on hatice2010\n",
      "\t\t[last] bacc: \t\t 0.8721\n",
      "\t\t[last] f1: \t\t 0.8564\n",
      "\t\t[last] precision: \t\t 0.8602\n",
      "\t\t[last] recall: \t\t 0.8527\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.8776\n",
      "\t\t[majority] f1: \t\t 0.8625\n",
      "\t\t[majority] precision: \t\t 0.8757\n",
      "\t\t[majority] recall: \t\t 0.8496\n",
      "\n",
      "\n",
      "\tTesting on nvb\n",
      "\t\t[last] bacc: \t\t 0.7590\n",
      "\t\t[last] f1: \t\t 0.2879\n",
      "\t\t[last] precision: \t\t 0.1766\n",
      "\t\t[last] recall: \t\t 0.7774\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.7881\n",
      "\t\t[majority] f1: \t\t 0.3424\n",
      "\t\t[majority] precision: \t\t 0.2200\n",
      "\t\t[majority] recall: \t\t 0.7722\n",
      "\n",
      "\n",
      "\t\t Total time taken: 80.72943329811096 s\n",
      "\n",
      "Loading model:\n",
      "\tvra1_nod_32ws_12f_16u.hdf5 \t #params: 1409\n",
      "\n",
      "\tTesting on vra1\n",
      "\t\t[last] bacc: \t\t 0.9057\n",
      "\t\t[last] f1: \t\t 0.6725\n",
      "\t\t[last] precision: \t\t 0.5255\n",
      "\t\t[last] recall: \t\t 0.9336\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.9018\n",
      "\t\t[majority] f1: \t\t 0.6783\n",
      "\t\t[majority] precision: \t\t 0.5378\n",
      "\t\t[majority] recall: \t\t 0.9180\n",
      "\n",
      "\n",
      "\tTesting on sewa\n",
      "\t\t[last] bacc: \t\t 0.7146\n",
      "\t\t[last] f1: \t\t 0.3077\n",
      "\t\t[last] precision: \t\t 0.2016\n",
      "\t\t[last] recall: \t\t 0.6500\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.7072\n",
      "\t\t[majority] f1: \t\t 0.2934\n",
      "\t\t[majority] precision: \t\t 0.1890\n",
      "\t\t[majority] recall: \t\t 0.6558\n",
      "\n",
      "\n",
      "\tTesting on hatice2010\n",
      "\t\t[last] bacc: \t\t 0.8113\n",
      "\t\t[last] f1: \t\t 0.7971\n",
      "\t\t[last] precision: \t\t 0.7261\n",
      "\t\t[last] recall: \t\t 0.8834\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.8121\n",
      "\t\t[majority] f1: \t\t 0.7980\n",
      "\t\t[majority] precision: \t\t 0.7264\n",
      "\t\t[majority] recall: \t\t 0.8852\n",
      "\n",
      "\n",
      "\tTesting on nvb\n",
      "\t\t[last] bacc: \t\t 0.7467\n",
      "\t\t[last] f1: \t\t 0.2579\n",
      "\t\t[last] precision: \t\t 0.1531\n",
      "\t\t[last] recall: \t\t 0.8169\n",
      "\n",
      "\t\t[majority] bacc: \t\t 0.7505\n",
      "\t\t[majority] f1: \t\t 0.2579\n",
      "\t\t[majority] precision: \t\t 0.1527\n",
      "\t\t[majority] recall: \t\t 0.8313\n",
      "\n",
      "\n",
      "\t\t Total time taken: 106.82548308372498 s\n",
      "\n",
      "Saved to ./test_results_nonS/test_results_nonS_nod_32ws_12f_16u.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################\n",
    "# For a given head gesture: perform all possible cross-dataset evaluations and save the results as one .pkl file\n",
    "#\n",
    "# Saved to the folder ./test_results_{S,nonS}\n",
    "# Filenames naming convention: test_results_{dataset_name}_{S,nonS}_{head_gesture}_{window_size}ws_{number_of_features}f_{model_architecture}.pkl \n",
    "#######################################################################################################################\n",
    "\n",
    "#############################################\n",
    "# Smooth the predicted labels?\n",
    "smooth_labels = False # Name infix *_nonS_*\n",
    "smooth_labels = True  # Name infix *_S_*\n",
    "#############################################\n",
    "\n",
    "HEAD_GESTURE = 'nod'\n",
    "# HEAD_GESTURE = 'shake'\n",
    "# HEAD_GESTURE = 'tilt'\n",
    "WINDOW_SIZE = 32\n",
    "N_FEATURES = 12\n",
    "# GRU_ARCH = [128]\n",
    "# GRU_ARCH = [32]\n",
    "GRU_ARCH = [16]\n",
    "# GRU_ARCH = [8]\n",
    "# GRU_ARCH = [4]\n",
    "\n",
    "dataset_type = f'{WINDOW_SIZE}ws_{N_FEATURES}f'\n",
    "model_type = f'{dataset_type}_{arch_to_str(GRU_ARCH)}u'\n",
    "\n",
    "metrics_names = ['bacc', 'f1', 'precision', 'recall']\n",
    "voting_strategies = ['last', 'majority']\n",
    "dataset_names = ['vra1', 'sewa', 'hatice2010', 'nvb']\n",
    "\n",
    "datasets_path_prefix = f'/home/ICT2000/jondras/dvra_datasets'\n",
    "checkpoints_path_prefix = f'/home/ICT2000/jondras/deep-virtual-rapport-agent/head_gesture_detector/checkpoints'\n",
    "\n",
    "test_results_type = f'test_results_S' if smooth_labels else f'test_results_nonS'\n",
    "if not os.path.exists(f'./test_results/{test_results_type}'):\n",
    "    os.makedirs(f'./test_results/{test_results_type}')\n",
    "    \n",
    "# Test results are saved as dictionary:\n",
    "#     test_results[train_dataset_name][test_dataset_name][voting_strategy][metric_name]\n",
    "test_results = dict()\n",
    "\n",
    "start_time = time.time()\n",
    "# Iterate over models trained on various datasets\n",
    "for model_path in sorted(glob.glob(f'{checkpoints_path_prefix}/*_{HEAD_GESTURE}_{model_type}.hdf5')):\n",
    "    \n",
    "    train_dataset_name = model_path.split('/')[-1].split('_')[0]\n",
    "    if train_dataset_name not in dataset_names: continue\n",
    "    test_results[train_dataset_name] = dict()\n",
    "    \n",
    "    # Load best model for this dataset\n",
    "    # local_start_time = time.time() \n",
    "    K.clear_session()\n",
    "    best_model = load_model(model_path)\n",
    "    print(f'Loading model:\\n\\t{model_path.split(\"/\")[-1]} \\t #params: {best_model.count_params()}\\n')  \n",
    "    # print(f'\\t\\t Time to load model: {time.time() - local_start_time} s')\n",
    "    \n",
    "    # Iterate over datasets to test the model\n",
    "    for test_dataset_name in dataset_names:\n",
    "          \n",
    "        test_results[train_dataset_name][test_dataset_name] = dict()\n",
    "        for vs in voting_strategies:\n",
    "            test_results[train_dataset_name][test_dataset_name][vs] = defaultdict(list)  \n",
    "\n",
    "        # Load testing data\n",
    "        # local_start_time = time.time() \n",
    "        print(f'\\tTesting on {test_dataset_name}')\n",
    "        data = np.load(f'{datasets_path_prefix}/{test_dataset_name}/segmented_datasets/{test_dataset_name}_{HEAD_GESTURE}_{dataset_type}.npz')\n",
    "        X_test,  Y_test  = data['X_test'],  data['Y_test']\n",
    "        # print(f'\\t\\t Time to load data: {time.time() - local_start_time} s')\n",
    "  \n",
    "        # local_start_time = time.time() \n",
    "        test_metrics = evaluate_custom_metrics(Y_true=Y_test, \n",
    "                                               Y_pred=best_model.predict_classes(X_test, \n",
    "                                                                                 batch_size=10000\n",
    "#                                                                                  batch_size=len(X_test)\n",
    "                                                                                ), \n",
    "                                               chunk_lens=data['test_len'], window_size=WINDOW_SIZE, \n",
    "                                               smooth=smooth_labels\n",
    "                                              )\n",
    "        # print(f'\\t\\t Time to calculate test metrics: {time.time() - local_start_time} s')\n",
    "        for vs in voting_strategies:\n",
    "            for mn in metrics_names:\n",
    "                test_results[train_dataset_name][test_dataset_name][vs][mn].append( test_metrics[vs][mn] )\n",
    "                print(f'\\t\\t[{vs}] {mn}: \\t\\t {test_metrics[vs][mn]:.4f}')\n",
    "            print()\n",
    "        print()        \n",
    "\n",
    "    print(f'\\t\\t Total time taken: {time.time() - start_time} s\\n')\n",
    "\n",
    "# Save test results (from all testing of the current model on all datasets)\n",
    "save_results_path = f'./test_results/{test_results_type}/{test_results_type}_{HEAD_GESTURE}_{model_type}.pkl'\n",
    "with open(save_results_path, 'wb') as pickle_filehandler:\n",
    "    pickle.dump(test_results, pickle_filehandler)\n",
    "print(f'Saved to {save_results_path}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_results_S_nod_32ws_12f_4u.pkl\n",
      "\n",
      "[last] bacc\n",
      "╒══════════════╤══════════╤══════════╤══════════════╤══════════╕\n",
      "│ Trained on   │   vra1   │   sewa   │  hatice2010  │   nvb    │\n",
      "╞══════════════╪══════════╪══════════╪══════════════╪══════════╡\n",
      "│ vra1         │ 0.873037 │ 0.697702 │   0.787067   │ 0.711335 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ sewa         │  0.7526  │ 0.804502 │   0.869937   │ 0.782271 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ hatice2010   │ 0.649203 │ 0.724418 │   0.933496   │ 0.740443 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ nvb          │ 0.731682 │ 0.745261 │   0.887106   │ 0.825396 │\n",
      "╘══════════════╧══════════╧══════════╧══════════════╧══════════╛\n",
      "\n",
      "[majority] bacc\n",
      "╒══════════════╤══════════╤══════════╤══════════════╤══════════╕\n",
      "│ Trained on   │   vra1   │   sewa   │  hatice2010  │   nvb    │\n",
      "╞══════════════╪══════════╪══════════╪══════════════╪══════════╡\n",
      "│ vra1         │ 0.872333 │ 0.697168 │   0.794234   │ 0.72273  │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ sewa         │ 0.742463 │ 0.790192 │   0.869828   │ 0.802127 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ hatice2010   │ 0.652612 │ 0.723983 │   0.933291   │ 0.755798 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ nvb          │ 0.731442 │ 0.739001 │   0.887577   │ 0.827638 │\n",
      "╘══════════════╧══════════╧══════════╧══════════════╧══════════╛\n",
      "\n",
      "test_results_S_nod_32ws_12f_8u.pkl\n",
      "\n",
      "[last] bacc\n",
      "╒══════════════╤══════════╤══════════╤══════════════╤══════════╕\n",
      "│ Trained on   │   vra1   │   sewa   │  hatice2010  │   nvb    │\n",
      "╞══════════════╪══════════╪══════════╪══════════════╪══════════╡\n",
      "│ vra1         │ 0.882147 │ 0.707495 │   0.810923   │ 0.737508 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ sewa         │ 0.754649 │ 0.837873 │   0.89161    │ 0.771274 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ hatice2010   │ 0.624205 │ 0.694318 │   0.945855   │ 0.698858 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ nvb          │ 0.728535 │ 0.742243 │   0.889422   │ 0.828227 │\n",
      "╘══════════════╧══════════╧══════════╧══════════════╧══════════╛\n",
      "\n",
      "[majority] bacc\n",
      "╒══════════════╤══════════╤══════════╤══════════════╤══════════╕\n",
      "│ Trained on   │   vra1   │   sewa   │  hatice2010  │   nvb    │\n",
      "╞══════════════╪══════════╪══════════╪══════════════╪══════════╡\n",
      "│ vra1         │ 0.881822 │ 0.703404 │   0.820223   │ 0.743632 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ sewa         │ 0.747808 │ 0.82178  │   0.895764   │ 0.795123 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ hatice2010   │ 0.635334 │ 0.694837 │   0.945161   │ 0.734609 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ nvb          │ 0.726588 │ 0.736006 │   0.887161   │ 0.83084  │\n",
      "╘══════════════╧══════════╧══════════╧══════════════╧══════════╛\n",
      "\n",
      "test_results_S_nod_32ws_12f_16u.pkl\n",
      "\n",
      "[last] bacc\n",
      "╒══════════════╤══════════╤══════════╤══════════════╤══════════╕\n",
      "│ Trained on   │   vra1   │   sewa   │  hatice2010  │   nvb    │\n",
      "╞══════════════╪══════════╪══════════╪══════════════╪══════════╡\n",
      "│ vra1         │ 0.909282 │ 0.730977 │   0.841472   │ 0.75609  │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ sewa         │ 0.763052 │ 0.848938 │   0.894579   │ 0.76242  │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ hatice2010   │ 0.616605 │ 0.648383 │   0.957094   │ 0.676081 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ nvb          │ 0.724445 │ 0.748945 │   0.881582   │ 0.83797  │\n",
      "╘══════════════╧══════════╧══════════╧══════════════╧══════════╛\n",
      "\n",
      "[majority] bacc\n",
      "╒══════════════╤══════════╤══════════╤══════════════╤══════════╕\n",
      "│ Trained on   │   vra1   │   sewa   │  hatice2010  │   nvb    │\n",
      "╞══════════════╪══════════╪══════════╪══════════════╪══════════╡\n",
      "│ vra1         │ 0.907407 │ 0.724054 │   0.844949   │ 0.760827 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ sewa         │ 0.754195 │ 0.832965 │   0.899727   │ 0.792094 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ hatice2010   │ 0.639266 │ 0.66218  │   0.956118   │ 0.720913 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ nvb          │ 0.721124 │ 0.741943 │    0.8848    │ 0.835759 │\n",
      "╘══════════════╧══════════╧══════════╧══════════════╧══════════╛\n",
      "\n",
      "test_results_S_nod_32ws_12f_32u.pkl\n",
      "\n",
      "[last] bacc\n",
      "╒══════════════╤══════════╤══════════╤══════════════╤══════════╕\n",
      "│ Trained on   │   vra1   │   sewa   │  hatice2010  │   nvb    │\n",
      "╞══════════════╪══════════╪══════════╪══════════════╪══════════╡\n",
      "│ vra1         │ 0.938662 │ 0.692273 │   0.838282   │ 0.746499 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ sewa         │ 0.752316 │ 0.882431 │   0.876497   │ 0.751533 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ hatice2010   │ 0.601154 │ 0.646205 │   0.966379   │ 0.648422 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ nvb          │ 0.733367 │ 0.737278 │   0.882394   │ 0.841426 │\n",
      "╘══════════════╧══════════╧══════════╧══════════════╧══════════╛\n",
      "\n",
      "[majority] bacc\n",
      "╒══════════════╤══════════╤══════════╤══════════════╤══════════╕\n",
      "│ Trained on   │   vra1   │   sewa   │  hatice2010  │   nvb    │\n",
      "╞══════════════╪══════════╪══════════╪══════════════╪══════════╡\n",
      "│ vra1         │ 0.933929 │ 0.698744 │   0.835118   │ 0.750925 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ sewa         │ 0.752047 │ 0.863013 │   0.882919   │ 0.776737 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ hatice2010   │ 0.624177 │ 0.668197 │   0.965221   │ 0.702818 │\n",
      "├──────────────┼──────────┼──────────┼──────────────┼──────────┤\n",
      "│ nvb          │ 0.727746 │ 0.731778 │   0.884634   │ 0.841419 │\n",
      "╘══════════════╧══════════╧══════════╧══════════════╧══════════╛\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################\n",
    "# Show cross-dataset testing summary in table\n",
    "#######################################################################################################################\n",
    "import pickle\n",
    "from tabulate import tabulate\n",
    "from utils import arch_to_str\n",
    "import numpy as np\n",
    "\n",
    "#############################################\n",
    "# Smooth the predicted labels?\n",
    "smooth_labels = False # Name infix *_nonS_*\n",
    "smooth_labels = True  # Name infix *_S_*\n",
    "#############################################\n",
    "\n",
    "HEAD_GESTURE = 'nod'\n",
    "WINDOW_SIZE = 32\n",
    "N_FEATURES = 12\n",
    "gru_archs = [\n",
    "    [4], [8], [16], [32]\n",
    "]\n",
    "# GRU_ARCH = [128]\n",
    "# GRU_ARCH = [32]\n",
    "# GRU_ARCH = [16]\n",
    "# GRU_ARCH = [8]\n",
    "# GRU_ARCH = [4]\n",
    "\n",
    "metrics_names = ['bacc', 'f1', 'precision', 'recall']\n",
    "voting_strategies = ['last', 'majority']\n",
    "dataset_names = ['vra1', 'sewa', 'hatice2010', 'nvb']\n",
    "\n",
    "dataset_type = f'{WINDOW_SIZE}ws_{N_FEATURES}f'\n",
    "\n",
    "for GRU_ARCH in gru_archs:\n",
    "\n",
    "    model_type = f'{dataset_type}_{arch_to_str(GRU_ARCH)}u'\n",
    "    test_results_type = f'test_results_S' if smooth_labels else f'test_results_nonS'\n",
    "\n",
    "    save_results_path = f'./test_results/{test_results_type}/{test_results_type}_{HEAD_GESTURE}_{model_type}.pkl'\n",
    "    print(f'{test_results_type}_{HEAD_GESTURE}_{model_type}.pkl\\n')\n",
    "\n",
    "    with open(save_results_path, 'rb') as pickle_filehandler:\n",
    "        d = pickle.load(pickle_filehandler)\n",
    "\n",
    "        ########################################################################################\n",
    "        # Print tables\n",
    "\n",
    "        headers = [\n",
    "            'Trained on', \n",
    "            *dataset_names\n",
    "        ]\n",
    "\n",
    "        for vs in voting_strategies:\n",
    "            for mn in ['bacc']:# metrics_names:\n",
    "                print(f'[{vs}] {mn}')\n",
    "                tab_data = np.empty((len(dataset_names), len(dataset_names)))\n",
    "\n",
    "                for i, train_dataset_name in enumerate(dataset_names):\n",
    "                    for j, test_dataset_name in enumerate(dataset_names):\n",
    "                        tab_data[i, j] = d[train_dataset_name][test_dataset_name][vs][mn][0]\n",
    "\n",
    "                print(tabulate(tab_data, headers=headers, \n",
    "                               tablefmt='fancy_grid', \n",
    "                               showindex=dataset_names, \n",
    "                               numalign='center'\n",
    "                              ))\n",
    "                # Table for LaTex\n",
    "    #             print(tabulate(tab_data, headers=headers, \n",
    "    #                            tablefmt='latex_booktabs', \n",
    "    #                            showindex=dataset_names, \n",
    "    #                            numalign='center'\n",
    "    #                           ))\n",
    "            print()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
